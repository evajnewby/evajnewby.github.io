[
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "Blog",
    "section": "",
    "text": "2017 Thomas Fire Analysis\n\n\n\nMEDS\n\n\n\nDetailed code on how to create the fire bounday, overlay onto a false color image, and vizualize the AQI change\n\n\n\nEva Newby\n\n\nDec 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog post title\n\n\n\nQuarto\n\n\nMEDS\n\n\n\na short catchy descriotion of the blogpost\n\n\n\nEva Newby\n\n\nOct 18, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html",
    "title": "2017 Thomas Fire Analysis",
    "section": "",
    "text": "The purpose of this analysis is to save a boundary for the 2017 Thomas Fire in California as a GeoJSON, to then be added ontop of the false color image in part 2. To do this, data of all California fires will need to be downloaded, explored, filtered, and saved.\nAdditionally, through working through the steps above, one will gain practice loading in shapefiles, cleaning the data, and filter to the appropriate fire.\n\n\n\nThe data is from the United States Geological Survey (USGS) and contains data for all California fire perimeters in several file formats compatible with python (GeoJSON, Shapefile, CSV, etc.). Some fires are not included due to records being lost or destroyed.\nData reference: U.S. Geological Survey (USGS). (2020). California Fire Perimeters (ALL). Data.gov. Retrieved November 19, 2024, from https://catalog.data.gov/dataset/california-fire-perimeters-all-b3436\n\n\n\n\n# Load Packages\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\n\n# Read in California fire perimeter data\nfp = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','California_Fire_Perimeters_(all)[1].shp')\nca_fires= gpd.read_file(fp)\n\n# Convert ca_fires column names to lower case, and remove any spaces. \nca_fires.columns = ca_fires.columns.str.lower().str.replace(' ', '_')\n\n# Filter fires gdf to 2017 Thomas fire\nthomas = ca_fires[(ca_fires['fire_name'] == 'THOMAS') & (ca_fires['year_'] == 2017)]\n\n# Plot Thomas fire gdf\nthomas.plot()\n\n# Save Thomas fire boundary as a GeoJSON file\nthomas.to_file(\"data/thomas.geojson\", driver='GeoJSON')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Load Packages\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\n\n\n# Get current working directory\nos.getcwd()\n\n'/Users/ejnewby/MEDS/EDS-220/eds220-hwk4'\n\n\n\n# Read in California fire perimeter data\nfp = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','California_Fire_Perimeters_(all)[1].shp')\nca_fires= gpd.read_file(fp)\n\n\n\n\n\n# View the first 3 rows of fires df\nca_fires.head(3)\n\n\n\n\n\n\n\n\nYEAR_\nSTATE\nAGENCY\nUNIT_ID\nFIRE_NAME\nINC_NUM\nALARM_DATE\nCONT_DATE\nCAUSE\nC_METHOD\nOBJECTIVE\nGIS_ACRES\nCOMMENTS\nCOMPLEX_NA\nIRWINID\nFIRE_NUM\nCOMPLEX_ID\nDECADES\ngeometry\n\n\n\n\n0\n2023\nCA\nCDF\nSKU\nWHITWORTH\n00004808\n2023-06-17\n2023-06-17\n5\n1\n1\n5.72913\nNone\nNone\n{7985848C-0AC2-4BA4-8F0E-29F778652E61}\nNone\nNone\n2020\nPOLYGON ((-13682443.000 5091132.739, -13682445...\n\n\n1\n2023\nCA\nLRA\nBTU\nKAISER\n00010225\n2023-06-02\n2023-06-02\n5\n1\n1\n13.60240\nNone\nNone\n{43EBCC88-B3AC-48EB-8EF5-417FE0939CCF}\nNone\nNone\n2020\nPOLYGON ((-13576727.142 4841226.161, -13576726...\n\n\n2\n2023\nCA\nCDF\nAEU\nJACKSON\n00017640\n2023-07-01\n2023-07-02\n2\n1\n1\n27.81450\nNone\nNone\n{B64E1355-BF1D-441A-95D0-BC1FBB93483B}\nNone\nNone\n2020\nPOLYGON ((-13459243.000 4621236.000, -13458968...\n\n\n\n\n\n\n\n\n# Column data types of ca_fires\nca_fires.dtypes\n\nYEAR_            int64\nSTATE           object\nAGENCY          object\nUNIT_ID         object\nFIRE_NAME       object\nINC_NUM         object\nALARM_DATE      object\nCONT_DATE       object\nCAUSE            int64\nC_METHOD         int64\nOBJECTIVE        int64\nGIS_ACRES      float64\nCOMMENTS        object\nCOMPLEX_NA      object\nIRWINID         object\nFIRE_NUM        object\nCOMPLEX_ID      object\nDECADES          int64\ngeometry      geometry\ndtype: object\n\n\n\n# ca_fires df info\nca_fires.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nRangeIndex: 22261 entries, 0 to 22260\nData columns (total 19 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   YEAR_       22261 non-null  int64   \n 1   STATE       22261 non-null  object  \n 2   AGENCY      22208 non-null  object  \n 3   UNIT_ID     22194 non-null  object  \n 4   FIRE_NAME   15672 non-null  object  \n 5   INC_NUM     21286 non-null  object  \n 6   ALARM_DATE  22261 non-null  object  \n 7   CONT_DATE   22261 non-null  object  \n 8   CAUSE       22261 non-null  int64   \n 9   C_METHOD    22261 non-null  int64   \n 10  OBJECTIVE   22261 non-null  int64   \n 11  GIS_ACRES   22261 non-null  float64 \n 12  COMMENTS    2707 non-null   object  \n 13  COMPLEX_NA  596 non-null    object  \n 14  IRWINID     2695 non-null   object  \n 15  FIRE_NUM    17147 non-null  object  \n 16  COMPLEX_ID  360 non-null    object  \n 17  DECADES     22261 non-null  int64   \n 18  geometry    22261 non-null  geometry\ndtypes: float64(1), geometry(1), int64(5), object(12)\nmemory usage: 3.2+ MB\n\n\n\n# Convert ca_fires column names to lower case, and remove any spaces. \nca_fires.columns = ca_fires.columns.str.lower().str.replace(' ', '_')\n\n\n# Check the outputs\nca_fires.head(3)\n\n\n\n\n\n\n\n\nyear_\nstate\nagency\nunit_id\nfire_name\ninc_num\nalarm_date\ncont_date\ncause\nc_method\nobjective\ngis_acres\ncomments\ncomplex_na\nirwinid\nfire_num\ncomplex_id\ndecades\ngeometry\n\n\n\n\n0\n2023\nCA\nCDF\nSKU\nWHITWORTH\n00004808\n2023-06-17\n2023-06-17\n5\n1\n1\n5.72913\nNone\nNone\n{7985848C-0AC2-4BA4-8F0E-29F778652E61}\nNone\nNone\n2020\nPOLYGON ((-13682443.000 5091132.739, -13682445...\n\n\n1\n2023\nCA\nLRA\nBTU\nKAISER\n00010225\n2023-06-02\n2023-06-02\n5\n1\n1\n13.60240\nNone\nNone\n{43EBCC88-B3AC-48EB-8EF5-417FE0939CCF}\nNone\nNone\n2020\nPOLYGON ((-13576727.142 4841226.161, -13576726...\n\n\n2\n2023\nCA\nCDF\nAEU\nJACKSON\n00017640\n2023-07-01\n2023-07-02\n2\n1\n1\n27.81450\nNone\nNone\n{B64E1355-BF1D-441A-95D0-BC1FBB93483B}\nNone\nNone\n2020\nPOLYGON ((-13459243.000 4621236.000, -13458968...\n\n\n\n\n\n\n\n\n# Filter fires df to 2017 Thomas fire\nthomas = ca_fires[(ca_fires['fire_name'] == 'THOMAS') & (ca_fires['year_'] == 2017)]\n\n\n# View Thomas gdf info\nthomas.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nIndex: 1 entries, 2654 to 2654\nData columns (total 19 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   year_       1 non-null      int64   \n 1   state       1 non-null      object  \n 2   agency      1 non-null      object  \n 3   unit_id     1 non-null      object  \n 4   fire_name   1 non-null      object  \n 5   inc_num     1 non-null      object  \n 6   alarm_date  1 non-null      object  \n 7   cont_date   1 non-null      object  \n 8   cause       1 non-null      int64   \n 9   c_method    1 non-null      int64   \n 10  objective   1 non-null      int64   \n 11  gis_acres   1 non-null      float64 \n 12  comments    1 non-null      object  \n 13  complex_na  0 non-null      object  \n 14  irwinid     0 non-null      object  \n 15  fire_num    0 non-null      object  \n 16  complex_id  0 non-null      object  \n 17  decades     1 non-null      int64   \n 18  geometry    1 non-null      geometry\ndtypes: float64(1), geometry(1), int64(5), object(12)\nmemory usage: 160.0+ bytes\n\n\n\n# CRS of thomas gdf\nthomas.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n# Plot the Thomas fire gdf\nthomas.plot()\n\n\n\n\n\n\n\n\n\n\n\nI chose the shapefile data from data.gov, as this was one of the first websites I found that was not through an ESRI platform. I chose to upload the shapefiles as this is what I had used in the past while working, and wanted more practice with what I had experienced in the industry.\nThrough the preliminary exploration, I was able to determine that the coordinate reference system is EPSG:4326, which is WGS 84, and that the coordinate system is projected. Additionally, viewing the datatypes was helpful to determine if any column data types needed to be changed (none needed changing).\nNow that the correct Thomas fire boundary has been filtered to, let’s save the file as a GeoJSON to be used in the fire scar portion of the analysis.\n\n# Save Thomas fire boundary as a GeoJSON file\nthomas.to_file(\"data/thomas.geojson\", driver='GeoJSON')"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#about",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#about",
    "title": "2017 Thomas Fire Analysis",
    "section": "",
    "text": "The purpose of this analysis is to save a boundary for the 2017 Thomas Fire in California as a GeoJSON, to then be added ontop of the false color image in part 2. To do this, data of all California fires will need to be downloaded, explored, filtered, and saved.\nAdditionally, through working through the steps above, one will gain practice loading in shapefiles, cleaning the data, and filter to the appropriate fire."
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#the-dataset",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#the-dataset",
    "title": "2017 Thomas Fire Analysis",
    "section": "",
    "text": "The data is from the United States Geological Survey (USGS) and contains data for all California fire perimeters in several file formats compatible with python (GeoJSON, Shapefile, CSV, etc.). Some fires are not included due to records being lost or destroyed.\nData reference: U.S. Geological Survey (USGS). (2020). California Fire Perimeters (ALL). Data.gov. Retrieved November 19, 2024, from https://catalog.data.gov/dataset/california-fire-perimeters-all-b3436"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#complete-workflow",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#complete-workflow",
    "title": "2017 Thomas Fire Analysis",
    "section": "",
    "text": "# Load Packages\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\n\n# Read in California fire perimeter data\nfp = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','California_Fire_Perimeters_(all)[1].shp')\nca_fires= gpd.read_file(fp)\n\n# Convert ca_fires column names to lower case, and remove any spaces. \nca_fires.columns = ca_fires.columns.str.lower().str.replace(' ', '_')\n\n# Filter fires gdf to 2017 Thomas fire\nthomas = ca_fires[(ca_fires['fire_name'] == 'THOMAS') & (ca_fires['year_'] == 2017)]\n\n# Plot Thomas fire gdf\nthomas.plot()\n\n# Save Thomas fire boundary as a GeoJSON file\nthomas.to_file(\"data/thomas.geojson\", driver='GeoJSON')"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#step-by-step-workflow",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#step-by-step-workflow",
    "title": "2017 Thomas Fire Analysis",
    "section": "",
    "text": "# Load Packages\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\n\n\n# Get current working directory\nos.getcwd()\n\n'/Users/ejnewby/MEDS/EDS-220/eds220-hwk4'\n\n\n\n# Read in California fire perimeter data\nfp = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','California_Fire_Perimeters_(all)[1].shp')\nca_fires= gpd.read_file(fp)\n\n\n\n\n\n# View the first 3 rows of fires df\nca_fires.head(3)\n\n\n\n\n\n\n\n\nYEAR_\nSTATE\nAGENCY\nUNIT_ID\nFIRE_NAME\nINC_NUM\nALARM_DATE\nCONT_DATE\nCAUSE\nC_METHOD\nOBJECTIVE\nGIS_ACRES\nCOMMENTS\nCOMPLEX_NA\nIRWINID\nFIRE_NUM\nCOMPLEX_ID\nDECADES\ngeometry\n\n\n\n\n0\n2023\nCA\nCDF\nSKU\nWHITWORTH\n00004808\n2023-06-17\n2023-06-17\n5\n1\n1\n5.72913\nNone\nNone\n{7985848C-0AC2-4BA4-8F0E-29F778652E61}\nNone\nNone\n2020\nPOLYGON ((-13682443.000 5091132.739, -13682445...\n\n\n1\n2023\nCA\nLRA\nBTU\nKAISER\n00010225\n2023-06-02\n2023-06-02\n5\n1\n1\n13.60240\nNone\nNone\n{43EBCC88-B3AC-48EB-8EF5-417FE0939CCF}\nNone\nNone\n2020\nPOLYGON ((-13576727.142 4841226.161, -13576726...\n\n\n2\n2023\nCA\nCDF\nAEU\nJACKSON\n00017640\n2023-07-01\n2023-07-02\n2\n1\n1\n27.81450\nNone\nNone\n{B64E1355-BF1D-441A-95D0-BC1FBB93483B}\nNone\nNone\n2020\nPOLYGON ((-13459243.000 4621236.000, -13458968...\n\n\n\n\n\n\n\n\n# Column data types of ca_fires\nca_fires.dtypes\n\nYEAR_            int64\nSTATE           object\nAGENCY          object\nUNIT_ID         object\nFIRE_NAME       object\nINC_NUM         object\nALARM_DATE      object\nCONT_DATE       object\nCAUSE            int64\nC_METHOD         int64\nOBJECTIVE        int64\nGIS_ACRES      float64\nCOMMENTS        object\nCOMPLEX_NA      object\nIRWINID         object\nFIRE_NUM        object\nCOMPLEX_ID      object\nDECADES          int64\ngeometry      geometry\ndtype: object\n\n\n\n# ca_fires df info\nca_fires.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nRangeIndex: 22261 entries, 0 to 22260\nData columns (total 19 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   YEAR_       22261 non-null  int64   \n 1   STATE       22261 non-null  object  \n 2   AGENCY      22208 non-null  object  \n 3   UNIT_ID     22194 non-null  object  \n 4   FIRE_NAME   15672 non-null  object  \n 5   INC_NUM     21286 non-null  object  \n 6   ALARM_DATE  22261 non-null  object  \n 7   CONT_DATE   22261 non-null  object  \n 8   CAUSE       22261 non-null  int64   \n 9   C_METHOD    22261 non-null  int64   \n 10  OBJECTIVE   22261 non-null  int64   \n 11  GIS_ACRES   22261 non-null  float64 \n 12  COMMENTS    2707 non-null   object  \n 13  COMPLEX_NA  596 non-null    object  \n 14  IRWINID     2695 non-null   object  \n 15  FIRE_NUM    17147 non-null  object  \n 16  COMPLEX_ID  360 non-null    object  \n 17  DECADES     22261 non-null  int64   \n 18  geometry    22261 non-null  geometry\ndtypes: float64(1), geometry(1), int64(5), object(12)\nmemory usage: 3.2+ MB\n\n\n\n# Convert ca_fires column names to lower case, and remove any spaces. \nca_fires.columns = ca_fires.columns.str.lower().str.replace(' ', '_')\n\n\n# Check the outputs\nca_fires.head(3)\n\n\n\n\n\n\n\n\nyear_\nstate\nagency\nunit_id\nfire_name\ninc_num\nalarm_date\ncont_date\ncause\nc_method\nobjective\ngis_acres\ncomments\ncomplex_na\nirwinid\nfire_num\ncomplex_id\ndecades\ngeometry\n\n\n\n\n0\n2023\nCA\nCDF\nSKU\nWHITWORTH\n00004808\n2023-06-17\n2023-06-17\n5\n1\n1\n5.72913\nNone\nNone\n{7985848C-0AC2-4BA4-8F0E-29F778652E61}\nNone\nNone\n2020\nPOLYGON ((-13682443.000 5091132.739, -13682445...\n\n\n1\n2023\nCA\nLRA\nBTU\nKAISER\n00010225\n2023-06-02\n2023-06-02\n5\n1\n1\n13.60240\nNone\nNone\n{43EBCC88-B3AC-48EB-8EF5-417FE0939CCF}\nNone\nNone\n2020\nPOLYGON ((-13576727.142 4841226.161, -13576726...\n\n\n2\n2023\nCA\nCDF\nAEU\nJACKSON\n00017640\n2023-07-01\n2023-07-02\n2\n1\n1\n27.81450\nNone\nNone\n{B64E1355-BF1D-441A-95D0-BC1FBB93483B}\nNone\nNone\n2020\nPOLYGON ((-13459243.000 4621236.000, -13458968...\n\n\n\n\n\n\n\n\n# Filter fires df to 2017 Thomas fire\nthomas = ca_fires[(ca_fires['fire_name'] == 'THOMAS') & (ca_fires['year_'] == 2017)]\n\n\n# View Thomas gdf info\nthomas.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nIndex: 1 entries, 2654 to 2654\nData columns (total 19 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   year_       1 non-null      int64   \n 1   state       1 non-null      object  \n 2   agency      1 non-null      object  \n 3   unit_id     1 non-null      object  \n 4   fire_name   1 non-null      object  \n 5   inc_num     1 non-null      object  \n 6   alarm_date  1 non-null      object  \n 7   cont_date   1 non-null      object  \n 8   cause       1 non-null      int64   \n 9   c_method    1 non-null      int64   \n 10  objective   1 non-null      int64   \n 11  gis_acres   1 non-null      float64 \n 12  comments    1 non-null      object  \n 13  complex_na  0 non-null      object  \n 14  irwinid     0 non-null      object  \n 15  fire_num    0 non-null      object  \n 16  complex_id  0 non-null      object  \n 17  decades     1 non-null      int64   \n 18  geometry    1 non-null      geometry\ndtypes: float64(1), geometry(1), int64(5), object(12)\nmemory usage: 160.0+ bytes\n\n\n\n# CRS of thomas gdf\nthomas.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n# Plot the Thomas fire gdf\nthomas.plot()\n\n\n\n\n\n\n\n\n\n\n\nI chose the shapefile data from data.gov, as this was one of the first websites I found that was not through an ESRI platform. I chose to upload the shapefiles as this is what I had used in the past while working, and wanted more practice with what I had experienced in the industry.\nThrough the preliminary exploration, I was able to determine that the coordinate reference system is EPSG:4326, which is WGS 84, and that the coordinate system is projected. Additionally, viewing the datatypes was helpful to determine if any column data types needed to be changed (none needed changing).\nNow that the correct Thomas fire boundary has been filtered to, let’s save the file as a GeoJSON to be used in the fire scar portion of the analysis.\n\n# Save Thomas fire boundary as a GeoJSON file\nthomas.to_file(\"data/thomas.geojson\", driver='GeoJSON')"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#about-1",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#about-1",
    "title": "2017 Thomas Fire Analysis",
    "section": "About",
    "text": "About\nThe purpose of this analysis is to create a false color image of southern Santa Barbara county using landsat data in the .nc file format, and overlay the 2017 Thomas fire boundary GeoJSON. The goal is to observe how the false color imagery illuminates the 2017 Thomas fire scar, and if that matches well with the boundary.\nAdditionally, practice with the rioxarray package and working with geoJSON files are important aspects of this assignment."
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#the-dataset-1",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#the-dataset-1",
    "title": "2017 Thomas Fire Analysis",
    "section": "The Dataset",
    "text": "The Dataset\nThe data is from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite, and contains several bands (red, green, blue, near-infrared and shortwave infrared). This dataset was retrieved from the Microsoft Planetary Computer data catalogue and pre-processed to remove data outside land and coarsen the spatial resolution.\nData reference: Microsoft. (n.d.). Landsat C2 L2 dataset. Planetary Computer. Retrieved November 19, 2024, from https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#complete-workflow-1",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#complete-workflow-1",
    "title": "2017 Thomas Fire Analysis",
    "section": "Complete Workflow",
    "text": "Complete Workflow\n\n# Load Packages\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\nimport rasterio\nimport numpy as np\nfrom shapely.geometry import box\n\n# Import .nc file using rioxr.open_rasterio\nfp2 = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','landsat8-2018-01-26-sb-simplified.nc')\nlandsat = rioxr.open_rasterio(fp2)\n\n# Drop the band dimension of the data using squeeze() and drop_vars().\nlandsat = landsat.squeeze().drop_vars('band')\n\n# Read-in thomas fire GeoJSON from part 1 notebook\nfp3 = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','thomas.geojson')\nthomas = gpd.read_file(fp3)\n\n# Change landsat to Projected CRS: EPSG:3857, since that matches the Thomas fire bounday\nlandsat = landsat.rio.reproject(\"EPSG:3857\")\n\n# Plot Landsat and Fire boundary data\nfig, ax = plt.subplots(figsize = (10, 10))\n\nlandsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(ax = ax, robust = True)\n\nthomas.boundary.plot(ax = ax, edgecolor = 'blue', linewidth = 2, label=\"Thomas Fire Boundary\")\n\nax.legend()\n\nax.set_title('2017 Thomas Fire Boundary Over False Color Imagery in Southwest Santa Barbara County, CA',\n             fontsize = 12)\n\nplt.show()"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#step-by-step-workflow-1",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#step-by-step-workflow-1",
    "title": "2017 Thomas Fire Analysis",
    "section": "Step-by-Step Workflow:",
    "text": "Step-by-Step Workflow:\n\n# Load Packages\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\nimport rasterio\nimport numpy as np\nfrom shapely.geometry import box\n\n\nImport Landsat Data (using server file path)\n\n\nExplore data\n\n# Import .nc file using rioxr.open_rasterio\nfp2 = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','landsat8-2018-01-26-sb-simplified.nc')\nlandsat = rioxr.open_rasterio(fp2)\n\n\n# View the landsat dataset\nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (band: 1, x: 870, y: 731)\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (band, y, x) float64 5MB ...\n    green        (band, y, x) float64 5MB ...\n    blue         (band, y, x) float64 5MB ...\n    nir08        (band, y, x) float64 5MB ...\n    swir22       (band, y, x) float64 5MB ...xarray.DatasetDimensions:band: 1x: 870y: 731Coordinates: (4)band(band)int641array([1])x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\n\n# View landsat dimensions\nlandsat.dims\n\nFrozenMappingWarningOnValuesAccess({'band': 1, 'x': 870, 'y': 731})\n\n\nData summary: - The variables are red, green, blue, nir08 (nir-infrared), and swir22(short-wave infrared). - The dimensions are 1 spectral band, 870 rows (height), and 731 columns (width)\n\n\nTrue Color Image\nTo create a true color image, the band dimensionss will need to be dropped.\n\n# Drop the band dimension of the data using squeeze() and drop_vars().\nlandsat = landsat.squeeze().drop_vars('band')\n\n# Confirm drop and squeeze\nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (x: 870, y: 731)\nCoordinates:\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (y, x) float64 5MB ...\n    green        (y, x) float64 5MB ...\n    blue         (y, x) float64 5MB ...\n    nir08        (y, x) float64 5MB ...\n    swir22       (y, x) float64 5MB ...xarray.DatasetDimensions:x: 870y: 731Coordinates: (3)x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (2)xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\n\n# Select red, green, and blue bands, convert to an array using `.to_array()`, and plot using `.imshow()`\n\nxr.Dataset(landsat[['red','green','blue']]).to_array().plot.imshow()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n# Adjust scale by setting robust parameter to true.\nxr.Dataset(landsat[['red','green','blue']]).to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\nCompare the ouputs\nThe first part gives a black and white output, while the second part gives the true colors. This is due to the robust parameter, which adjusts the color scale using data percentiles instead of minimum and maximum values, therefore excluding some extreme outliers that were influencing the scaling of the image as observed in part a.\n\n\n\nFalse Color Image\nTo create a false color image for the true color image above, the short-wave infrared, near wave infrared, and red variables will need to be plotted in that order.\n\n# Create a false color image by plotting swir22, nir08, and red. \nlandsat_false = xr.Dataset(landsat[['swir22','nir08','red']]).to_array().plot.imshow(robust = True)\n\n\n\n\n\n\n\n\n\n\nMap\nNow that we have a false color image with a fire scar in the southwestern section of the image, let’s load in the 2017 Thomas fire perimeter GeoJson ontop. From this map, we can observe how closely the fire perimeter matches with the fire scar.\n\n# Read-in thomas fire data from other notebook\nfp3 = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','thomas.geojson')\nthomas = gpd.read_file(fp3)\n\n\n# Check CRS of thomas fire boundary data\nprint(f\"{'The CRS of the landsat data is':&lt;27}{thomas.crs}\")\n\nThe CRS of the landsat data isEPSG:3857\n\n\n\n# Check CRS for landsat data\nprint(f\"{'The CRS of the landsat data is':&lt;27}{landsat.rio.crs}\")\n\nThe CRS of the landsat data isEPSG:32611\n\n\n\n# Change landsat to Projected CRS: EPSG:3857, since that matches the Thomas fire bounday\nlandsat = landsat.rio.reproject(\"EPSG:3857\")\n\n# Verify change\nprint(f\"{'The CRS of the landsat data is':&lt;27}{landsat.rio.crs}\")\nprint(f\"{'The CRS of the landsat data is':&lt;27}{thomas.crs}\")\n\nThe CRS of the landsat data isEPSG:3857\nThe CRS of the landsat data isEPSG:3857\n\n\n\n# Plot Landsat and Fire boundary data\nfig, ax = plt.subplots(figsize = (10, 10))\n\nlandsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(ax = ax, robust = True)\n\nthomas.boundary.plot(ax = ax, edgecolor = 'blue', linewidth = 2, label=\"Thomas Fire Boundary\")\n\nax.legend()\n\nax.set_title('2017 Thomas Fire Boundary Over False Color Imagery in Southwest Santa Barbara County, CA',\n             fontsize = 12)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nMap Description:\nThe map above shows how false color imagery is being used to greater illuminate the 2017 Thomas fire boundary. As areas that were burned more recently will have different and younger vegetation (also more likely to have non-native species after burning), the chlorophyll content of the vegetation differences will show more drastically in a false color image than a true color image as they reflect different wavelengths back, which cannot be seen in the visible spectrum. One can see how the 2017 Thomas fire boundary matches up pretty closely with the burned areas showing up as orange-red."
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#about-2",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#about-2",
    "title": "2017 Thomas Fire Analysis",
    "section": "About",
    "text": "About\nThe 2017 Thomas fire devastated the Santa Barbara region, burning 281,893 acres over 39 days and completely surrounded the Ojai region and skyrocketing the AQI. The purpose of this analysis is to visualize the impact of the AQI on the 2017 Thomas Fire in Santa Barbara County.\nSource: California Department of Forestry and Fire Protection. (2017, December 4). Thomas Fire. California Department of Forestry and Fire Protection. https://www.fire.ca.gov/incidents/2017/12/4/thomas-fire"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#the-dataset-2",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#the-dataset-2",
    "title": "2017 Thomas Fire Analysis",
    "section": "The Dataset",
    "text": "The Dataset\nIn this task you will use Air Quality Index (AQI) data from the US Environmental Protection Agency. The data is located at the EPA’s website on Air Quality Data Collected at Outdoor Monitors Across the US."
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#instructions-to-read-in-data-from-the-url",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#instructions-to-read-in-data-from-the-url",
    "title": "2017 Thomas Fire Analysis",
    "section": "Instructions to Read-in Data from the URL:",
    "text": "Instructions to Read-in Data from the URL:\nUnder “Donwload Data”, click on “Pre-generated Data Files”, then click on “Tables of Daily AQI”. Copy the URL to the 2017 Daily AQI by County ZIP file daily_aqi_by_county_2017.zip. Then, read in the data from the URL using the pd.read_csv function with the compression='zip' parameter added and store it as aqi_17. Do the same for 2018."
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#complete-workflow-2",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#complete-workflow-2",
    "title": "2017 Thomas Fire Analysis",
    "section": "Complete Workflow",
    "text": "Complete Workflow\n\nimport pandas as pd\nimport numpy as np \n\n# Read in data\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\", compression='zip')\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\", compression='zip')\n\n# Glue 2017 and 2018 data together \naqi = pd.concat([aqi_17, aqi_18])\n\n# Initial column names: notice caps and spaces (difficult to work with!)\nprint(aqi.columns, '\\n') # View names of columns, with a new line.\n\n# Simplify column names\naqi.columns = (aqi.columns # column names\n                  .str.lower() # convert to lower case\n                  .str.replace(' ','_') # remove blank space by putting a \"_\" instead\n                )\nprint(aqi.columns, '\\n') # View names of columns, with a new line.\n\n# Select only from SB county\naqi_sb = aqi[aqi['county_name'] == \"Santa Barbara\"]\n\n# Drop specified columns\naqi_sb = aqi_sb.drop(['state_name', 'county_name', 'state_code', 'county_code'], axis=1)\n\n# Update to pandas.datetime object\naqi_sb.date = pd.to_datetime(aqi_sb['date'])\n\n# Update the index\naqi_sb = aqi_sb.set_index('date')\n\n# Calculate AQI rolling average over 5 days\nrolling_average = aqi_sb['aqi'].rolling('5D').mean()\n\n# Add mean of AQI over 5-day rolling window to a new column\naqi_sb['five_day_average'] = rolling_average\n\n# Create Plot\naqi_sb[['aqi', 'five_day_average']].plot(xlabel = 'Year',\n      ylabel = 'Air Quality Index (AQI)',\n      title = 'Air Quality Index (AQI) from 2017-2018',\n     label = 'Daily AQI')\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object') \n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object')"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#step-by-step-workflow-2",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#step-by-step-workflow-2",
    "title": "2017 Thomas Fire Analysis",
    "section": "Step-by-Step Workflow",
    "text": "Step-by-Step Workflow\n\n# Load packages\nimport pandas as pd\nimport numpy as np \n\n\nImport Data\n\n# Read in data\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\", compression='zip')\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\", compression='zip')\n\n\n\nExplore Data\n\n# First 5 rows of each dataset\naqi_17.head()\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n28\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n29\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2017-01-10\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2017-01-13\n40\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2017-01-16\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\naqi_18.head()\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2018-01-02\n42\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2018-01-05\n45\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2018-01-08\n20\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2018-01-11\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2018-01-14\n33\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n# More detailed information from `info`\naqi_17.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 326801 entries, 0 to 326800\nData columns (total 10 columns):\n #   Column                     Non-Null Count   Dtype \n---  ------                     --------------   ----- \n 0   State Name                 326801 non-null  object\n 1   county Name                326801 non-null  object\n 2   State Code                 326801 non-null  int64 \n 3   County Code                326801 non-null  int64 \n 4   Date                       326801 non-null  object\n 5   AQI                        326801 non-null  int64 \n 6   Category                   326801 non-null  object\n 7   Defining Parameter         326801 non-null  object\n 8   Defining Site              326801 non-null  object\n 9   Number of Sites Reporting  326801 non-null  int64 \ndtypes: int64(4), object(6)\nmemory usage: 24.9+ MB\n\n\n\n# Data Exploration\naqi_18.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 327543 entries, 0 to 327542\nData columns (total 10 columns):\n #   Column                     Non-Null Count   Dtype \n---  ------                     --------------   ----- \n 0   State Name                 327543 non-null  object\n 1   county Name                327543 non-null  object\n 2   State Code                 327543 non-null  int64 \n 3   County Code                327543 non-null  int64 \n 4   Date                       327543 non-null  object\n 5   AQI                        327543 non-null  int64 \n 6   Category                   327543 non-null  object\n 7   Defining Parameter         327543 non-null  object\n 8   Defining Site              327543 non-null  object\n 9   Number of Sites Reporting  327543 non-null  int64 \ndtypes: int64(4), object(6)\nmemory usage: 25.0+ MB\n\n\n\nWhy Explore?\ndf.info() and df.head() give the amount and number of categories, the class, and number of entries as well as the first 5 rows. Knowing the data types of each column may also be helpful information for the future operations we want to perform.\n\n\n\nCombining Data Frames\nWe currently have two separate data frames. For this exercise we will need to “glue” them one on top of the other. The pandas function pd.concat() can achieve this.\nPass [aqi_17, aqi_18] as the input of pd.concat() and store the output as aqi.\nIn the next line run aqi.\nNOTE: When we concatenate data frames like this, without any extra parameters for pd.concat() the indices for the two dataframes are just “glued together”, the index of the resulting dataframe is not updated to start from 0. Notice the mismatch between the index of aqi and the number of rows i the complete data frame.\n\n# Glue 2017 and 2018 data together \naqi = pd.concat([aqi_17, aqi_18])\n\n# View data frame\naqi\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n28\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n29\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2017-01-10\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2017-01-13\n40\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2017-01-16\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n327538\nWyoming\nWeston\n56\n45\n2018-12-27\n36\nGood\nOzone\n56-045-0003\n1\n\n\n327539\nWyoming\nWeston\n56\n45\n2018-12-28\n35\nGood\nOzone\n56-045-0003\n1\n\n\n327540\nWyoming\nWeston\n56\n45\n2018-12-29\n35\nGood\nOzone\n56-045-0003\n1\n\n\n327541\nWyoming\nWeston\n56\n45\n2018-12-30\n31\nGood\nOzone\n56-045-0003\n1\n\n\n327542\nWyoming\nWeston\n56\n45\n2018-12-31\n35\nGood\nOzone\n56-045-0003\n1\n\n\n\n\n654344 rows × 10 columns\n\n\n\n\n\nClean Data\n\n# Initial column names: notice caps and spaces\nprint(aqi.columns, '\\n') # View names of columns, with a new line.\n\n# Simplify column names\naqi.columns = (aqi.columns # column names\n                  .str.lower() # convert to lower case\n                  .str.replace(' ','_') # remove blank space by putting a \"_\" instead\n                )\nprint(aqi.columns, '\\n') # View names of columns, with a new line.\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object') \n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object') \n\n\n\n\nSelect only data from Santa Barbara county and store it in a new variable aqi_sb.\nRemove the state_name, county_name, state_code and county_code columns from aqi_sb. Your dataframe should have the following columns in this order: date, aqi, category, defining_parameter, defining_stie, number_of_sites_reporting.\n\n# Select only from SB county\naqi_sb = aqi[aqi['county_name'] == \"Santa Barbara\"]\n\n# Drop specified columns\naqi_sb = aqi_sb.drop(['state_name', 'county_name', 'state_code', 'county_code'], axis=1)\n\naqi_sb\n\n\n\n\n\n\n\n\ndate\naqi\ncategory\ndefining_parameter\ndefining_site\nnumber_of_sites_reporting\n\n\n\n\n28648\n2017-01-01\n39\nGood\nOzone\n06-083-4003\n12\n\n\n28649\n2017-01-02\n39\nGood\nPM2.5\n06-083-2011\n11\n\n\n28650\n2017-01-03\n71\nModerate\nPM10\n06-083-4003\n12\n\n\n28651\n2017-01-04\n34\nGood\nOzone\n06-083-4003\n13\n\n\n28652\n2017-01-05\n37\nGood\nOzone\n06-083-4003\n12\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n29128\n2018-12-27\n37\nGood\nOzone\n06-083-1025\n11\n\n\n29129\n2018-12-28\n39\nGood\nOzone\n06-083-1021\n12\n\n\n29130\n2018-12-29\n39\nGood\nOzone\n06-083-1021\n12\n\n\n29131\n2018-12-30\n41\nGood\nPM2.5\n06-083-1008\n12\n\n\n29132\n2018-12-31\n38\nGood\nOzone\n06-083-2004\n12\n\n\n\n\n730 rows × 6 columns\n\n\n\n\n\n\nConvert to pandas.datetime and update index\nTo create a 5-day rolling average of AQI in the next section, the date column of aqi_sb needs to be updated to a pandas.datetime object and the index needs to be set to date.\n\n# Update to pandas.datetime object\naqi_sb.date = pd.to_datetime(aqi_sb['date'])\n\n# Update the index\naqi_sb = aqi_sb.set_index('date')\n\n\n\nCreate a Rolling Average Over 5 Days\nCalculate an average over a rolling window using the rolling()method for pandas.Series:\n\nSpecify what we want to calculate over each window.\nUse the aggregator function mean() to calculate the average over each window\nthe parameter ‘5D’ indicates the window for our rolling average is 5 days.\nOuput is a pandas.Series\n\n\n# Calculate AQI rolling average over 5 days\nrolling_average = aqi_sb['aqi'].rolling('5D').mean()\n\n# View values\nrolling_average\n\ndate\n2017-01-01    39.000000\n2017-01-02    39.000000\n2017-01-03    49.666667\n2017-01-04    45.750000\n2017-01-05    44.000000\n                ...    \n2018-12-27    41.200000\n2018-12-28    38.600000\n2018-12-29    38.200000\n2018-12-30    38.200000\n2018-12-31    38.800000\nName: aqi, Length: 730, dtype: float64\n\n\n\nAdd the mean to a new column\n\n# Add mean of AQI over 5-day rolling window to a new column\naqi_sb['five_day_average'] = rolling_average\n\n# View data frame to confirm new column\naqi_sb\n\n\n\n\n\n\n\n\naqi\ncategory\ndefining_parameter\ndefining_site\nnumber_of_sites_reporting\nfive_day_average\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n2017-01-01\n39\nGood\nOzone\n06-083-4003\n12\n39.000000\n\n\n2017-01-02\n39\nGood\nPM2.5\n06-083-2011\n11\n39.000000\n\n\n2017-01-03\n71\nModerate\nPM10\n06-083-4003\n12\n49.666667\n\n\n2017-01-04\n34\nGood\nOzone\n06-083-4003\n13\n45.750000\n\n\n2017-01-05\n37\nGood\nOzone\n06-083-4003\n12\n44.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n2018-12-27\n37\nGood\nOzone\n06-083-1025\n11\n41.200000\n\n\n2018-12-28\n39\nGood\nOzone\n06-083-1021\n12\n38.600000\n\n\n2018-12-29\n39\nGood\nOzone\n06-083-1021\n12\n38.200000\n\n\n2018-12-30\n41\nGood\nPM2.5\n06-083-1008\n12\n38.200000\n\n\n2018-12-31\n38\nGood\nOzone\n06-083-2004\n12\n38.800000\n\n\n\n\n730 rows × 6 columns\n\n\n\n\n\n\nVizualize\nOne way to visualize the data is to create a line plot showing both the daily AQI and the 5-day average (5-day average on top of the AQI).\n\n# Create AQI Plot\naqi_sb[['aqi', 'five_day_average']].plot(xlabel = 'Year',\n      ylabel = 'Air Quality Index (AQI)',\n      title = 'Air Quality Index (AQI) from 2017-2018',\n     label = 'Daily AQI')\n\n\n\n\n\n\n\n\n\nPlot Description:\nNote the AQI spike in December at the time of the Thomas fire. The spike is less pronounced with the five-day average, but still very noticeable. It appears that the AQI returned to normal levels once the fire was extinguished."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Eva Newby",
    "section": "",
    "text": "Eva Newby is a graduate student in the UC Santa Barbara Bren School of Environmental Science and Management, working towards a Master’s degree in Environmental Data Science. Eva graduated with Regents Scholar distinction from UC Davis (2019) with a B.S. in Animal Science and a specialization in Animal Behavior. Since graduation, she has been volunteering at North America’s largest refugee camp in Tijuana, Mexico and working as a biologist in the environmental consulting field. In addition to her responsibilities as a biologist, Eva became the head drone pilot for the Southern California region, exposing her to even more of California’s diverse ecosystems. Drone imagery data synthesis initially sparked her interest in the data science field, and the curiosity to use data science to further inform sound environmental decision making drove her to apply to the Bren School. Eva additionally plans to use her data science skills to help address food insecurity in impoverished communities.\nOutside of her professional career, Eva enjoys the great outdoors through surfing, biking, rock climbing, snowboarding, hiking, and petting as many friendly animals as possible."
  }
]