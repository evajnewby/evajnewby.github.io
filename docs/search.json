[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Eva’s Favorite Resources",
    "section": "",
    "text": "As an environmental data scientist, I find myself using certain websites and resources more than others. Here is an (ongoing) list of resources I’ve found helpful!\n\nDesign\nCoolors is one of my go-tos for finding a color palette. Just click the space bar to change the colors, and have fun!\nGoogle fonts has many font options to suit your fancy (and project).\n\n\nWhich visualization is best for my data?\nFrom data to viz is a favorite for many reasons. The site is easy to navigate and presents SO many options. The best part? The flowchart. Check it out!\n\n\nWho is using environmental data science?\nGoogle Sustainability is investing quite a bit into various environmental data research projects. Check out this post on 6 ways google has advanced energy solutions last year."
  },
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "Blog",
    "section": "",
    "text": "Loggerhead Sea Turtle Nesting Trends\n\n\n\nQuarto\n\n\nMEDS\n\n\n\nfor the Caribbean and Gulf of Mexico Region from 1979 to 2023\n\n\n\nEva Newby\n\n\nMar 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2017 Thomas Fire Analysis\n\n\n\nMEDS\n\n\n\nDetailed code on how to create the fire bounday, overlay onto a false color image, and vizualize the AQI change\n\n\n\nEva Newby\n\n\nDec 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeach Closure Days as a Function of Rainfall in Coastal San Diego County\n\n\n\nQuarto\n\n\nMEDS\n\n\n\nCode in R using a negative binomial regression model\n\n\n\nEva Newby\n\n\nDec 11, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blogs/2024-12-11-Rainfall-and-Beach-Closures/index.html",
    "href": "blogs/2024-12-11-Rainfall-and-Beach-Closures/index.html",
    "title": "Beach Closure Days as a Function of Rainfall in Coastal San Diego County",
    "section": "",
    "text": "Repository Link"
  },
  {
    "objectID": "blogs/2024-12-11-Rainfall-and-Beach-Closures/index.html#project-description",
    "href": "blogs/2024-12-11-Rainfall-and-Beach-Closures/index.html#project-description",
    "title": "Beach Closure Days as a Function of Rainfall in Coastal San Diego County",
    "section": "Project Description",
    "text": "Project Description\nCoastal San Diego County is known for many things; most notable are the world class beaches with surfable waves year-round and sunny days, driving locals and tourists alike to the coast. San Diego is also known for it’s mild climate, boasting warm winters with generally low precipitation. However, the effects of climate change have undoubtedly brought more extreme weather to the region, including precipitation. A 2017 article from UC Merced in conjunction with Univeristy of California, San Diego’s Scripps Institute of Oceanography predicts “the region will have 16 percent fewer rainy days, but 8 percent more rain during large, intense storms, which could lead to more frequent flooding. In addition to property damage and disruption of transportation, flooding leads to our ocean becoming more polluted”. Additionally, the article notes that flooding leads to wetlands’ impaired ability to act as pollution filters for runoff into the ocean. There is some local knowledge of this phenomena already. Growing up in north county San Diego as a surfer, I was taught to not enter the ocean for 24-72 hours after a “big rain”, as the water was likely polluted and to avoid sickness. As climate change continues to affect the world, it is important to understand just how related rainfall is with extreme water quality advisories that warrant closing of a beach, and the potential hindering of an coastline economy. Could rainfall be the key component to predicting beach closures?\nThe interaction I aim to assess in this blog post is the cumulative amount of rain in inches from 2 coastal San Diego County stations, Oceanside Harbor and San Diego International Airport, compared to the total beach closure days for the beaches in San Diego County. The data was collected on a monthly basis from January 1, 2016 through April 1, 2020. The number of beach closure days (total_closure_beach_days) will be modeled as a function of the total rainfall (rain_inch_total) in the following analysis.\nThe water quality advisories data was accessed from San Diego County’s online data catalog. The precipitation data for the two collection stations was accessed from the California Department of Water Resources Query System."
  },
  {
    "objectID": "blogs/2024-12-11-Rainfall-and-Beach-Closures/index.html#load-in-data",
    "href": "blogs/2024-12-11-Rainfall-and-Beach-Closures/index.html#load-in-data",
    "title": "Beach Closure Days as a Function of Rainfall in Coastal San Diego County",
    "section": "Load-in Data:",
    "text": "Load-in Data:\nRead in data from data folder:\n\n# Water Quality Advisories\nwqa &lt;- read_csv(here(\"data\", \"Department_of_Environmental_Health_Beach_Water_Quality_Advisories_20241203.csv\")) %&gt;% \n  mutate(Date = str_replace(Date, \"AM\", \"\")) %&gt;% \n  mutate(Date = str_replace(Date, \"12:00:00\", \"\"))%&gt;% \n mutate(Date = str_trim(Date))\n\n# Precipitation Data\nsd_precip &lt;- read_csv(here(\"data\", \"SDG_PRECIP.csv\"))"
  },
  {
    "objectID": "blogs/2024-12-11-Rainfall-and-Beach-Closures/index.html#clean-data",
    "href": "blogs/2024-12-11-Rainfall-and-Beach-Closures/index.html#clean-data",
    "title": "Beach Closure Days as a Function of Rainfall in Coastal San Diego County",
    "section": "Clean Data:",
    "text": "Clean Data:\nTo more efficiently work with the data, let’s convert to lower case, remove any spaces, check the data types of our columns, and remove any columns not needed for this analysis.\n\n# Clean column names, convert to lower case\ncolnames(wqa) &lt;- tolower(colnames(wqa))\ncolnames(sd_precip) &lt;- tolower(colnames(sd_precip))\n\n# Remove spaces\ncolnames(wqa) &lt;- gsub(\" \", \"_\", colnames(wqa))\ncolnames(sd_precip) &lt;- gsub(\" \", \"_\", colnames(sd_precip))\n\n# Remove preceding zeros in wqa date column\nwqa$date &lt;- sub(\"^0\", \"\", wqa$date)\n\n\n# Check class of date columns\nprint(class(sd_precip$date))\n\n[1] \"character\"\n\nprint(class(wqa$date))\n\n[1] \"character\"\n\n# Convert from character to datetime\nsd_precip$date &lt;- mdy(sd_precip$date)\nwqa$date &lt;- mdy(wqa$date)\n\n# Confirm conversion\nprint(class(sd_precip$date))\n\n[1] \"Date\"\n\nprint(class(wqa$date))\n\n[1] \"Date\"\n\n\n\n# Set days equal to the 1st, keep only months since we are doing a monthly analysis\nwqa$date &lt;- floor_date(wqa$date, unit = \"month\")\n\n\n# Remove columns we don't need\nwqa &lt;- subset(wqa, select = c(date, total_closure_beach_days))\n\nsd_precip &lt;- subset(sd_precip, select = -c(rain_inches_sd, rain_inches_osm))\n\nNow that we have all our data tidy, let’s join our tables together to prepare for further analysis.\n\n# Join tables\nwqa_sd_precip &lt;- full_join(wqa, sd_precip, by = \"date\")"
  },
  {
    "objectID": "blogs/2024-12-11-Rainfall-and-Beach-Closures/index.html#citations",
    "href": "blogs/2024-12-11-Rainfall-and-Beach-Closures/index.html#citations",
    "title": "Beach Closure Days as a Function of Rainfall in Coastal San Diego County",
    "section": "Citations:",
    "text": "Citations:\nCalifornia Department of Water Resources. CDEC Query Monthly. California Data Exchange Center. Retrieved December 5, 2024, from https://cdec.water.ca.gov/dynamicapp/QueryMonthly\nKPBS. (2022, December 28). Swimmers, beware: Rain brings contaminated urban runoff to beaches. KPBS. https://www.kpbs.org/news/environment/2022/12/28/swimmers-beware-rain-brings-contaminated-urban-runoff-to-beaches\nSan Diego County. April 2, 2020. Beach water quality advisories. Open Data Portal. Retrieved November 12, 2024, from https://data.sandiegocounty.gov/stories/s/32jp-ecqs\nSnRI. (2017, October 30). Look at climate change effects in San Diego County. University of California, Merced. https://snri.ucmerced.edu/news/2017/look-climate-change-effects-san-diego-county"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Eva",
    "section": "",
    "text": "Data Science (R, Python, SQL)\n\n\nEcology\n\n\nEnergy\n\n\nDrones"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html",
    "title": "2017 Thomas Fire Analysis",
    "section": "",
    "text": "More detailed content is available in the repository’s README.md\n\n\nThe purpose of this analysis is to save a boundary for the 2017 Thomas Fire in California as a GeoJSON, to then be added ontop of the false color image in part 2. To do this, data of all California fires will need to be downloaded, explored, filtered, and saved.\nAdditionally, through working through the steps above, one will gain practice loading in shapefiles, cleaning the data, and filter to the appropriate fire.\n\n\n\n\nWrangling geospatial raster data using the rioxarray package\nSaving geospatial data as a GeoJSON\nCreating a true color image using the RGB (red, green, and blue) bands\nCreating a false color image by rearranging bands to incorporate near-infrared and short-wave-infrared\nVisualize the 2017 Thomas fire’s effect on AQI\n\n\n\n\nThe data is from the United States Geological Survey (USGS) and contains data for all California fire perimeters in several file formats compatible with python (GeoJSON, Shapefile, CSV, etc.). Some fires are not included due to records being lost or destroyed.\n\n# load Packages\nimport os\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport rioxarray as rioxr\nimport xarray as xr\nimport pandas as pd\n\n\n\n\n\n# Load Packages\nimport os\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Read in California fire perimeter data\nfp = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','California_Fire_Perimeters_(all)[1].shp')\nca_fires= gpd.read_file(fp)\n\n# Convert ca_fires column names to lower case, and remove any spaces. \nca_fires.columns = ca_fires.columns.str.lower().str.replace(' ', '_')\n\n# Filter fires gdf to 2017 Thomas fire\nthomas = ca_fires[(ca_fires['fire_name'] == 'THOMAS') & (ca_fires['year_'] == 2017)]\n\n# Plot Thomas fire gdf\nthomas.plot()\n\n# Save Thomas fire boundary as a GeoJSON file\nthomas.to_file(\"data/thomas.geojson\", driver='GeoJSON')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Get current working directory\nos.getcwd()\n\n'/Users/ejnewby/MEDS/EDS-220/eds220-hwk4'\n\n\n\n# Read in California fire perimeter data\nfp = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','California_Fire_Perimeters_(all)[1].shp')\nca_fires= gpd.read_file(fp)\n\n\n\n\nTidy data will make filtering to the Thomas fire easier.\n\n# View the first 3 rows of fires df\nca_fires.head(3)\n\n\n\n\n\n\n\n\nYEAR_\nSTATE\nAGENCY\nUNIT_ID\nFIRE_NAME\nINC_NUM\nALARM_DATE\nCONT_DATE\nCAUSE\nC_METHOD\nOBJECTIVE\nGIS_ACRES\nCOMMENTS\nCOMPLEX_NA\nIRWINID\nFIRE_NUM\nCOMPLEX_ID\nDECADES\ngeometry\n\n\n\n\n0\n2023\nCA\nCDF\nSKU\nWHITWORTH\n00004808\n2023-06-17\n2023-06-17\n5\n1\n1\n5.72913\nNone\nNone\n{7985848C-0AC2-4BA4-8F0E-29F778652E61}\nNone\nNone\n2020\nPOLYGON ((-13682443.000 5091132.739, -13682445...\n\n\n1\n2023\nCA\nLRA\nBTU\nKAISER\n00010225\n2023-06-02\n2023-06-02\n5\n1\n1\n13.60240\nNone\nNone\n{43EBCC88-B3AC-48EB-8EF5-417FE0939CCF}\nNone\nNone\n2020\nPOLYGON ((-13576727.142 4841226.161, -13576726...\n\n\n2\n2023\nCA\nCDF\nAEU\nJACKSON\n00017640\n2023-07-01\n2023-07-02\n2\n1\n1\n27.81450\nNone\nNone\n{B64E1355-BF1D-441A-95D0-BC1FBB93483B}\nNone\nNone\n2020\nPOLYGON ((-13459243.000 4621236.000, -13458968...\n\n\n\n\n\n\n\n\n# ca_fires df info\nca_fires.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nRangeIndex: 22261 entries, 0 to 22260\nData columns (total 19 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   YEAR_       22261 non-null  int64   \n 1   STATE       22261 non-null  object  \n 2   AGENCY      22208 non-null  object  \n 3   UNIT_ID     22194 non-null  object  \n 4   FIRE_NAME   15672 non-null  object  \n 5   INC_NUM     21286 non-null  object  \n 6   ALARM_DATE  22261 non-null  object  \n 7   CONT_DATE   22261 non-null  object  \n 8   CAUSE       22261 non-null  int64   \n 9   C_METHOD    22261 non-null  int64   \n 10  OBJECTIVE   22261 non-null  int64   \n 11  GIS_ACRES   22261 non-null  float64 \n 12  COMMENTS    2707 non-null   object  \n 13  COMPLEX_NA  596 non-null    object  \n 14  IRWINID     2695 non-null   object  \n 15  FIRE_NUM    17147 non-null  object  \n 16  COMPLEX_ID  360 non-null    object  \n 17  DECADES     22261 non-null  int64   \n 18  geometry    22261 non-null  geometry\ndtypes: float64(1), geometry(1), int64(5), object(12)\nmemory usage: 3.2+ MB\n\n\n\n\n\nThis will help with filtering in the next step.\n\n# Convert ca_fires column names to lower case, and remove any spaces. \nca_fires.columns = ca_fires.columns.str.lower().str.replace(' ', '_')\n\n\n# Check the outputs\nca_fires.head(3)\n\n\n\n\n\n\n\n\nyear_\nstate\nagency\nunit_id\nfire_name\ninc_num\nalarm_date\ncont_date\ncause\nc_method\nobjective\ngis_acres\ncomments\ncomplex_na\nirwinid\nfire_num\ncomplex_id\ndecades\ngeometry\n\n\n\n\n0\n2023\nCA\nCDF\nSKU\nWHITWORTH\n00004808\n2023-06-17\n2023-06-17\n5\n1\n1\n5.72913\nNone\nNone\n{7985848C-0AC2-4BA4-8F0E-29F778652E61}\nNone\nNone\n2020\nPOLYGON ((-13682443.000 5091132.739, -13682445...\n\n\n1\n2023\nCA\nLRA\nBTU\nKAISER\n00010225\n2023-06-02\n2023-06-02\n5\n1\n1\n13.60240\nNone\nNone\n{43EBCC88-B3AC-48EB-8EF5-417FE0939CCF}\nNone\nNone\n2020\nPOLYGON ((-13576727.142 4841226.161, -13576726...\n\n\n2\n2023\nCA\nCDF\nAEU\nJACKSON\n00017640\n2023-07-01\n2023-07-02\n2\n1\n1\n27.81450\nNone\nNone\n{B64E1355-BF1D-441A-95D0-BC1FBB93483B}\nNone\nNone\n2020\nPOLYGON ((-13459243.000 4621236.000, -13458968...\n\n\n\n\n\n\n\nNow that the data has been cleaned, let’s filter the ca_fires geodataframe to the 2017 Thomas fire and plot the output.\n\n# Filter fires gdf to 2017 Thomas fire\nthomas = ca_fires[(ca_fires['fire_name'] == 'THOMAS') & (ca_fires['year_'] == 2017)]\n\n\n# CRS of thomas gdf\nthomas.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n# Plot the Thomas fire gdf\nthomas.plot()\n\n\n\n\n\n\n\n\n\n\nI chose the shapefile data from data.gov, as this was one of the first websites I found that was not through an ESRI platform. I chose to upload the shapefiles as this is what I had used in the past while working, and wanted more practice with what I had experienced in the industry.\nThrough the preliminary exploration, I was able to determine that the coordinate reference system is EPSG:4326, which is WGS 84, and that the coordinate system is projected. Additionally, viewing the datatypes was helpful to determine if any column data types needed to be changed (none needed changing).\nNow that the correct Thomas fire boundary has been filtered to, let’s save the file as a GeoJSON to be used in the fire scar portion of the analysis.\n\n# Save Thomas fire boundary as a GeoJSON file\nthomas.to_file(\"data/thomas.geojson\", driver='GeoJSON')"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#about",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#about",
    "title": "2017 Thomas Fire Analysis",
    "section": "",
    "text": "The purpose of this analysis is to save a boundary for the 2017 Thomas Fire in California as a GeoJSON, to then be added ontop of the false color image in part 2. To do this, data of all California fires will need to be downloaded, explored, filtered, and saved.\nAdditionally, through working through the steps above, one will gain practice loading in shapefiles, cleaning the data, and filter to the appropriate fire."
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#highlights",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#highlights",
    "title": "2017 Thomas Fire Analysis",
    "section": "",
    "text": "Wrangling geospatial raster data using the rioxarray package\nSaving geospatial data as a GeoJSON\nCreating a true color image using the RGB (red, green, and blue) bands\nCreating a false color image by rearranging bands to incorporate near-infrared and short-wave-infrared\nVisualize the 2017 Thomas fire’s effect on AQI"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#the-dataset",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#the-dataset",
    "title": "2017 Thomas Fire Analysis",
    "section": "",
    "text": "The data is from the United States Geological Survey (USGS) and contains data for all California fire perimeters in several file formats compatible with python (GeoJSON, Shapefile, CSV, etc.). Some fires are not included due to records being lost or destroyed.\n\n# load Packages\nimport os\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport rioxarray as rioxr\nimport xarray as xr\nimport pandas as pd"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#complete-workflow",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#complete-workflow",
    "title": "2017 Thomas Fire Analysis",
    "section": "",
    "text": "# Load Packages\nimport os\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Read in California fire perimeter data\nfp = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','California_Fire_Perimeters_(all)[1].shp')\nca_fires= gpd.read_file(fp)\n\n# Convert ca_fires column names to lower case, and remove any spaces. \nca_fires.columns = ca_fires.columns.str.lower().str.replace(' ', '_')\n\n# Filter fires gdf to 2017 Thomas fire\nthomas = ca_fires[(ca_fires['fire_name'] == 'THOMAS') & (ca_fires['year_'] == 2017)]\n\n# Plot Thomas fire gdf\nthomas.plot()\n\n# Save Thomas fire boundary as a GeoJSON file\nthomas.to_file(\"data/thomas.geojson\", driver='GeoJSON')"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#step-by-step-workflow",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#step-by-step-workflow",
    "title": "2017 Thomas Fire Analysis",
    "section": "",
    "text": "# Get current working directory\nos.getcwd()\n\n'/Users/ejnewby/MEDS/EDS-220/eds220-hwk4'\n\n\n\n# Read in California fire perimeter data\nfp = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','California_Fire_Perimeters_(all)[1].shp')\nca_fires= gpd.read_file(fp)\n\n\n\n\nTidy data will make filtering to the Thomas fire easier.\n\n# View the first 3 rows of fires df\nca_fires.head(3)\n\n\n\n\n\n\n\n\nYEAR_\nSTATE\nAGENCY\nUNIT_ID\nFIRE_NAME\nINC_NUM\nALARM_DATE\nCONT_DATE\nCAUSE\nC_METHOD\nOBJECTIVE\nGIS_ACRES\nCOMMENTS\nCOMPLEX_NA\nIRWINID\nFIRE_NUM\nCOMPLEX_ID\nDECADES\ngeometry\n\n\n\n\n0\n2023\nCA\nCDF\nSKU\nWHITWORTH\n00004808\n2023-06-17\n2023-06-17\n5\n1\n1\n5.72913\nNone\nNone\n{7985848C-0AC2-4BA4-8F0E-29F778652E61}\nNone\nNone\n2020\nPOLYGON ((-13682443.000 5091132.739, -13682445...\n\n\n1\n2023\nCA\nLRA\nBTU\nKAISER\n00010225\n2023-06-02\n2023-06-02\n5\n1\n1\n13.60240\nNone\nNone\n{43EBCC88-B3AC-48EB-8EF5-417FE0939CCF}\nNone\nNone\n2020\nPOLYGON ((-13576727.142 4841226.161, -13576726...\n\n\n2\n2023\nCA\nCDF\nAEU\nJACKSON\n00017640\n2023-07-01\n2023-07-02\n2\n1\n1\n27.81450\nNone\nNone\n{B64E1355-BF1D-441A-95D0-BC1FBB93483B}\nNone\nNone\n2020\nPOLYGON ((-13459243.000 4621236.000, -13458968...\n\n\n\n\n\n\n\n\n# ca_fires df info\nca_fires.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nRangeIndex: 22261 entries, 0 to 22260\nData columns (total 19 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   YEAR_       22261 non-null  int64   \n 1   STATE       22261 non-null  object  \n 2   AGENCY      22208 non-null  object  \n 3   UNIT_ID     22194 non-null  object  \n 4   FIRE_NAME   15672 non-null  object  \n 5   INC_NUM     21286 non-null  object  \n 6   ALARM_DATE  22261 non-null  object  \n 7   CONT_DATE   22261 non-null  object  \n 8   CAUSE       22261 non-null  int64   \n 9   C_METHOD    22261 non-null  int64   \n 10  OBJECTIVE   22261 non-null  int64   \n 11  GIS_ACRES   22261 non-null  float64 \n 12  COMMENTS    2707 non-null   object  \n 13  COMPLEX_NA  596 non-null    object  \n 14  IRWINID     2695 non-null   object  \n 15  FIRE_NUM    17147 non-null  object  \n 16  COMPLEX_ID  360 non-null    object  \n 17  DECADES     22261 non-null  int64   \n 18  geometry    22261 non-null  geometry\ndtypes: float64(1), geometry(1), int64(5), object(12)\nmemory usage: 3.2+ MB\n\n\n\n\n\nThis will help with filtering in the next step.\n\n# Convert ca_fires column names to lower case, and remove any spaces. \nca_fires.columns = ca_fires.columns.str.lower().str.replace(' ', '_')\n\n\n# Check the outputs\nca_fires.head(3)\n\n\n\n\n\n\n\n\nyear_\nstate\nagency\nunit_id\nfire_name\ninc_num\nalarm_date\ncont_date\ncause\nc_method\nobjective\ngis_acres\ncomments\ncomplex_na\nirwinid\nfire_num\ncomplex_id\ndecades\ngeometry\n\n\n\n\n0\n2023\nCA\nCDF\nSKU\nWHITWORTH\n00004808\n2023-06-17\n2023-06-17\n5\n1\n1\n5.72913\nNone\nNone\n{7985848C-0AC2-4BA4-8F0E-29F778652E61}\nNone\nNone\n2020\nPOLYGON ((-13682443.000 5091132.739, -13682445...\n\n\n1\n2023\nCA\nLRA\nBTU\nKAISER\n00010225\n2023-06-02\n2023-06-02\n5\n1\n1\n13.60240\nNone\nNone\n{43EBCC88-B3AC-48EB-8EF5-417FE0939CCF}\nNone\nNone\n2020\nPOLYGON ((-13576727.142 4841226.161, -13576726...\n\n\n2\n2023\nCA\nCDF\nAEU\nJACKSON\n00017640\n2023-07-01\n2023-07-02\n2\n1\n1\n27.81450\nNone\nNone\n{B64E1355-BF1D-441A-95D0-BC1FBB93483B}\nNone\nNone\n2020\nPOLYGON ((-13459243.000 4621236.000, -13458968...\n\n\n\n\n\n\n\nNow that the data has been cleaned, let’s filter the ca_fires geodataframe to the 2017 Thomas fire and plot the output.\n\n# Filter fires gdf to 2017 Thomas fire\nthomas = ca_fires[(ca_fires['fire_name'] == 'THOMAS') & (ca_fires['year_'] == 2017)]\n\n\n# CRS of thomas gdf\nthomas.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n# Plot the Thomas fire gdf\nthomas.plot()\n\n\n\n\n\n\n\n\n\n\nI chose the shapefile data from data.gov, as this was one of the first websites I found that was not through an ESRI platform. I chose to upload the shapefiles as this is what I had used in the past while working, and wanted more practice with what I had experienced in the industry.\nThrough the preliminary exploration, I was able to determine that the coordinate reference system is EPSG:4326, which is WGS 84, and that the coordinate system is projected. Additionally, viewing the datatypes was helpful to determine if any column data types needed to be changed (none needed changing).\nNow that the correct Thomas fire boundary has been filtered to, let’s save the file as a GeoJSON to be used in the fire scar portion of the analysis.\n\n# Save Thomas fire boundary as a GeoJSON file\nthomas.to_file(\"data/thomas.geojson\", driver='GeoJSON')"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#about-1",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#about-1",
    "title": "2017 Thomas Fire Analysis",
    "section": "About",
    "text": "About\nThe purpose of this analysis is to create a false color image of southern Santa Barbara county using landsat data in the .nc file format, and overlay the 2017 Thomas fire boundary GeoJSON. The goal is to observe how the false color imagery illuminates the 2017 Thomas fire scar, and if that matches well with the boundary.\nAdditionally, practice with the rioxarray package and working with geoJSON files are important aspects of this assignment."
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#the-dataset-1",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#the-dataset-1",
    "title": "2017 Thomas Fire Analysis",
    "section": "The Dataset",
    "text": "The Dataset\nThe data is from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite, and contains several bands (red, green, blue, near-infrared and shortwave infrared). This dataset was retrieved from the Microsoft Planetary Computer data catalogue and pre-processed to remove data outside land and coarsen the spatial resolution."
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#complete-workflow-1",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#complete-workflow-1",
    "title": "2017 Thomas Fire Analysis",
    "section": "Complete Workflow",
    "text": "Complete Workflow\n\n# Load Packages\nimport os\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport rioxarray as rioxr\nimport xarray as xr\n\n# Import .nc file using rioxr.open_rasterio\nfp2 = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','landsat8-2018-01-26-sb-simplified.nc')\nlandsat = rioxr.open_rasterio(fp2)\n\n# Drop the band dimension of the data using squeeze() and drop_vars().\nlandsat = landsat.squeeze().drop_vars('band')\n\n# Read-in thomas fire GeoJSON from part 1 notebook\nfp3 = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','thomas.geojson')\nthomas = gpd.read_file(fp3)\n\n# Change landsat to Projected CRS: EPSG:3857, since that matches the Thomas fire bounday\nlandsat = landsat.rio.reproject(\"EPSG:3857\")\n\n# Plot Landsat and Fire boundary data\nfig, ax = plt.subplots(figsize = (10, 10))\n\nlandsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(ax = ax, robust = True)\n\nthomas.boundary.plot(ax = ax, edgecolor = 'blue', linewidth = 2, label=\"Thomas Fire Boundary\")\n\nax.legend()\n\nax.set_title('2017 Thomas Fire Boundary Over False Color Imagery in Southwest Santa Barbara County, CA',\n             fontsize = 12)\n\nplt.show()"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#step-by-step-workflow-1",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#step-by-step-workflow-1",
    "title": "2017 Thomas Fire Analysis",
    "section": "Step-by-Step Workflow:",
    "text": "Step-by-Step Workflow:\n\nImport Landsat Data (using server file path)\n\n\nExplore data\n\n# Import .nc file using rioxr.open_rasterio\nfp2 = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','landsat8-2018-01-26-sb-simplified.nc')\nlandsat = rioxr.open_rasterio(fp2)\n\n\n# View the landsat dataset\nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (band: 1, x: 870, y: 731)\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (band, y, x) float64 5MB ...\n    green        (band, y, x) float64 5MB ...\n    blue         (band, y, x) float64 5MB ...\n    nir08        (band, y, x) float64 5MB ...\n    swir22       (band, y, x) float64 5MB ...xarray.DatasetDimensions:band: 1x: 870y: 731Coordinates: (4)band(band)int641array([1])x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\n\n# View landsat dimensions\nlandsat.dims\n\nFrozenMappingWarningOnValuesAccess({'band': 1, 'x': 870, 'y': 731})\n\n\nData summary: - The variables are red, green, blue, nir08 (nir-infrared), and swir22(short-wave infrared). - The dimensions are 1 spectral band, 870 rows (height), and 731 columns (width)\n\n\nTrue color image\nBefore creating a false color image, let’s see what the true color image looks like. To create a true color image, the band dimensionss will need to be dropped.\n\n# Drop the band dimension of the data using squeeze() and drop_vars().\nlandsat = landsat.squeeze().drop_vars('band')\n\n# Confirm drop and squeeze\nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (x: 870, y: 731)\nCoordinates:\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (y, x) float64 5MB ...\n    green        (y, x) float64 5MB ...\n    blue         (y, x) float64 5MB ...\n    nir08        (y, x) float64 5MB ...\n    swir22       (y, x) float64 5MB ...xarray.DatasetDimensions:x: 870y: 731Coordinates: (3)x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (2)xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\nNow that the bands have been dropped, let’s select the red, green, and blue bands for plotting.\n\n# Select red, green, and blue bands, convert to an array using `.to_array()`, and plot using `.imshow()`\n\nxr.Dataset(landsat[['red','green','blue']]).to_array().plot.imshow()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nWhy is the above plot in black and white only? This is due to the robust parameter within .imshow().\n\n# Adjust scale by setting robust parameter to true.\nxr.Dataset(landsat[['red','green','blue']]).to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\nCompare the ouputs:\nThe first part gives a black and white output, while the second part gives the true colors. This is due to the robust parameter, which adjusts the color scale using data percentiles instead of minimum and maximum values, therefore excluding some extreme outliers that were influencing the scaling of the image as observed in part a.\n\n\nFalse color image\nNow that we’ve seen the true color image, let’s create a false color image. To create a false color image for the true color image above, the short-wave infrared, near wave infrared, and red variables will need to be plotted in that order.\n\n# Create a false color image by plotting swir22, nir08, and red. \nlandsat_false = xr.Dataset(landsat[['swir22','nir08','red']]).to_array().plot.imshow(robust = True)\n\n\n\n\n\n\n\n\n\n\nMap the results\nNow that we have a false color image with a fire scar in the southwestern section of the image, let’s load in the 2017 Thomas fire perimeter GeoJson ontop. From this map, we can observe how closely the fire perimeter matches with the fire scar.\nCheck the CRS’ for both geodataframes to ensure plotting compatibility.\n\n# Read-in thomas fire data from above\nfp3 = os.path.join('/', 'Users', 'ejnewby', 'MEDS', 'EDS-220', 'eds220-hwk4', 'data','thomas.geojson')\nthomas = gpd.read_file(fp3)\n\n\n# Check CRS of thomas fire boundary data\nprint(f\"{'The CRS of the landsat data is':&lt;27}{thomas.crs}\")\n\nThe CRS of the landsat data isEPSG:3857\n\n\n\n# Check CRS for landsat data\nprint(f\"{'The CRS of the landsat data is':&lt;27}{landsat.rio.crs}\")\n\nThe CRS of the landsat data isEPSG:32611\n\n\n\n# Change landsat to Projected CRS: EPSG:3857, since that matches the Thomas fire bounday\nlandsat = landsat.rio.reproject(\"EPSG:3857\")\n\n# Verify change\nprint(f\"{'The CRS of the landsat data is':&lt;27}{landsat.rio.crs}\")\nprint(f\"{'The CRS of the landsat data is':&lt;27}{thomas.crs}\")\n\nThe CRS of the landsat data isEPSG:3857\nThe CRS of the landsat data isEPSG:3857\n\n\nNow that the CRS’ are confirmed to match, let’s plot!\n\n# Plot Landsat and Fire boundary data\nfig, ax = plt.subplots(figsize = (10, 10))\n\nlandsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(ax = ax, robust = True)\n\nthomas.boundary.plot(ax = ax, edgecolor = 'blue', linewidth = 2, label=\"Thomas Fire Boundary\")\n\nax.legend()\n\nax.set_title('2017 Thomas Fire Boundary Over False Color Imagery in Southwest Santa Barbara County, CA',\n             fontsize = 12)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nMap description:\nThe map above shows how false color imagery is being used to greater illuminate the 2017 Thomas fire boundary. As areas that were burned more recently will have different and younger vegetation (also more likely to have non-native species after burning), the chlorophyll content of the vegetation differences will show more drastically in a false color image than a true color image as they reflect different wavelengths back, which cannot be seen in the visible spectrum. One can see how the 2017 Thomas fire boundary matches up pretty closely with the burned areas showing up as orange-red."
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#about-2",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#about-2",
    "title": "2017 Thomas Fire Analysis",
    "section": "About",
    "text": "About\nThe 2017 Thomas fire devastated the Santa Barbara region, burning 281,893 acres over 39 days and completely surrounded the Ojai region and skyrocketing the AQI. The purpose of this analysis is to visualize the impact of the AQI on the 2017 Thomas Fire in Santa Barbara County."
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#the-dataset-2",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#the-dataset-2",
    "title": "2017 Thomas Fire Analysis",
    "section": "The Dataset",
    "text": "The Dataset\nIn this task you will use Air Quality Index (AQI) data from the US Environmental Protection Agency. The data is located at the EPA’s website on Air Quality Data Collected at Outdoor Monitors Across the US."
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#instructions-to-read-in-data-from-the-url",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#instructions-to-read-in-data-from-the-url",
    "title": "2017 Thomas Fire Analysis",
    "section": "Instructions to Read-in Data from the URL:",
    "text": "Instructions to Read-in Data from the URL:\nUnder “Donwload Data”, click on “Pre-generated Data Files”, then click on “Tables of Daily AQI”. Copy the URL to the 2017 Daily AQI by County ZIP file daily_aqi_by_county_2017.zip. Then, read in the data from the URL using the pd.read_csv function with the compression='zip' parameter added and store it as aqi_17. Do the same for 2018."
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#complete-workflow-2",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#complete-workflow-2",
    "title": "2017 Thomas Fire Analysis",
    "section": "Complete Workflow",
    "text": "Complete Workflow\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Read in data\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\", compression='zip')\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\", compression='zip')\n\n# Glue 2017 and 2018 data together \naqi = pd.concat([aqi_17, aqi_18])\n\n# Initial column names: notice caps and spaces (difficult to work with!)\nprint(aqi.columns, '\\n') # View names of columns, with a new line.\n\n# Simplify column names\naqi.columns = (aqi.columns # column names\n                  .str.lower() # convert to lower case\n                  .str.replace(' ','_') # remove blank space by putting a \"_\" instead\n                )\nprint(aqi.columns, '\\n') # View names of columns, with a new line.\n\n# Select only from SB county\naqi_sb = aqi[aqi['county_name'] == \"Santa Barbara\"]\n\n# Drop specified columns\naqi_sb = aqi_sb.drop(['state_name', 'county_name', 'state_code', 'county_code'], axis=1)\n\n# Update to pandas.datetime object\naqi_sb.date = pd.to_datetime(aqi_sb['date'])\n\n# Update the index\naqi_sb = aqi_sb.set_index('date')\n\n# Calculate AQI rolling average over 5 days\nrolling_average = aqi_sb['aqi'].rolling('5D').mean()\n\n# Add mean of AQI over 5-day rolling window to a new column\naqi_sb['five_day_average'] = rolling_average\n\n# Create AQI plot\nax = aqi_sb[['aqi', 'five_day_average']].plot(xlabel='Year', \n                                              ylabel='Air Quality Index (AQI)', \n                                              title='Air Quality Index (AQI) from 2017-2018')\n\n# Updating the legend with custom labels\nax.legend(['Daily AQI', '5-Day Average AQI'], loc='upper right')\n\n# Show the plot\nplt.show()\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object') \n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object')"
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#step-by-step-workflow-2",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#step-by-step-workflow-2",
    "title": "2017 Thomas Fire Analysis",
    "section": "Step-by-Step Workflow",
    "text": "Step-by-Step Workflow\n\nImport Data\nThis data is located on the EPA’s website and can be accessed from the links below.\n\n# Read in data\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\", compression='zip')\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\", compression='zip')\n\n\n\nExplore data\n\n# First 3 rows of 2017 dataset\naqi_17.head(3)\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n28\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n29\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2017-01-10\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n# First 3 rows of 2018 dataset\naqi_18.head(3)\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2018-01-02\n42\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2018-01-05\n45\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2018-01-08\n20\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n# More detailed information from `info` for 2017\naqi_17.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 326801 entries, 0 to 326800\nData columns (total 10 columns):\n #   Column                     Non-Null Count   Dtype \n---  ------                     --------------   ----- \n 0   State Name                 326801 non-null  object\n 1   county Name                326801 non-null  object\n 2   State Code                 326801 non-null  int64 \n 3   County Code                326801 non-null  int64 \n 4   Date                       326801 non-null  object\n 5   AQI                        326801 non-null  int64 \n 6   Category                   326801 non-null  object\n 7   Defining Parameter         326801 non-null  object\n 8   Defining Site              326801 non-null  object\n 9   Number of Sites Reporting  326801 non-null  int64 \ndtypes: int64(4), object(6)\nmemory usage: 24.9+ MB\n\n\n\n# More detailed information from `info` for 2018\naqi_18.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 327543 entries, 0 to 327542\nData columns (total 10 columns):\n #   Column                     Non-Null Count   Dtype \n---  ------                     --------------   ----- \n 0   State Name                 327543 non-null  object\n 1   county Name                327543 non-null  object\n 2   State Code                 327543 non-null  int64 \n 3   County Code                327543 non-null  int64 \n 4   Date                       327543 non-null  object\n 5   AQI                        327543 non-null  int64 \n 6   Category                   327543 non-null  object\n 7   Defining Parameter         327543 non-null  object\n 8   Defining Site              327543 non-null  object\n 9   Number of Sites Reporting  327543 non-null  int64 \ndtypes: int64(4), object(6)\nmemory usage: 25.0+ MB\n\n\n\nWhy explore?\ndf.info() and df.head(3) give the amount and number of categories, the class, and number of entries as well as the first 3 rows. Knowing the data types of each column may also be helpful information for the future operations we want to perform.\n\n\n\nCombining data frames\nWe currently have two separate data frames. We will need to “glue” them one on top of the other for our analysis. The pandas function pd.concat() can achieve this.\n\n# Glue 2017 and 2018 data together \naqi = pd.concat([aqi_17, aqi_18])\n\n# View data frame\naqi\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n28\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n29\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2017-01-10\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2017-01-13\n40\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2017-01-16\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n327538\nWyoming\nWeston\n56\n45\n2018-12-27\n36\nGood\nOzone\n56-045-0003\n1\n\n\n327539\nWyoming\nWeston\n56\n45\n2018-12-28\n35\nGood\nOzone\n56-045-0003\n1\n\n\n327540\nWyoming\nWeston\n56\n45\n2018-12-29\n35\nGood\nOzone\n56-045-0003\n1\n\n\n327541\nWyoming\nWeston\n56\n45\n2018-12-30\n31\nGood\nOzone\n56-045-0003\n1\n\n\n327542\nWyoming\nWeston\n56\n45\n2018-12-31\n35\nGood\nOzone\n56-045-0003\n1\n\n\n\n\n654344 rows × 10 columns\n\n\n\nWhen we concatenate data frames like this, without any extra parameters for pd.concat() the indices for the two dataframes are just “glued together”, the index of the resulting dataframe is not updated to start from 0. Notice the mismatch between the index of aqi and the number of rows in the complete data frame.\n\n\nClean data\nCleaning the data’s column names will\n\n# Initial column names\nprint(aqi.columns, '\\n') # View names of columns, with a new line.\n\n# Simplify column names\naqi.columns = (aqi.columns # column names\n                  .str.lower() # convert to lower case\n                  .str.replace(' ','_') # remove blank space by putting a \"_\" instead\n                )\nprint(aqi.columns, '\\n') # View names of columns, with a new line.\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object') \n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object') \n\n\n\nNow that our column names are simplified, let’s select only data from Santa Barbara county and store it in a new variable aqi_sb.\nRemove the state_name, county_name, state_code and county_code columns from aqi_sb. The dataframe should have the following columns in this order: date, aqi, category, defining_parameter, defining_stie, number_of_sites_reporting.\n\n# Select only from SB county\naqi_sb = aqi[aqi['county_name'] == \"Santa Barbara\"]\n\n# Drop specified columns\naqi_sb = aqi_sb.drop(['state_name', 'county_name', 'state_code', 'county_code'], axis=1)\n\naqi_sb\n\n\n\n\n\n\n\n\ndate\naqi\ncategory\ndefining_parameter\ndefining_site\nnumber_of_sites_reporting\n\n\n\n\n28648\n2017-01-01\n39\nGood\nOzone\n06-083-4003\n12\n\n\n28649\n2017-01-02\n39\nGood\nPM2.5\n06-083-2011\n11\n\n\n28650\n2017-01-03\n71\nModerate\nPM10\n06-083-4003\n12\n\n\n28651\n2017-01-04\n34\nGood\nOzone\n06-083-4003\n13\n\n\n28652\n2017-01-05\n37\nGood\nOzone\n06-083-4003\n12\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n29128\n2018-12-27\n37\nGood\nOzone\n06-083-1025\n11\n\n\n29129\n2018-12-28\n39\nGood\nOzone\n06-083-1021\n12\n\n\n29130\n2018-12-29\n39\nGood\nOzone\n06-083-1021\n12\n\n\n29131\n2018-12-30\n41\nGood\nPM2.5\n06-083-1008\n12\n\n\n29132\n2018-12-31\n38\nGood\nOzone\n06-083-2004\n12\n\n\n\n\n730 rows × 6 columns\n\n\n\nNext, we need to convert to pandas.datetime and update index.\nTo create a 5-day rolling average of AQI in the next section, the date column of aqi_sb needs to be updated to a pandas.datetime object and the index needs to be set to date.\n\n# Update to pandas.datetime object\naqi_sb.date = pd.to_datetime(aqi_sb['date'])\n\n# Update the index\naqi_sb = aqi_sb.set_index('date')\n\nNext, we need to create a rolling average over 5 days. This is best accomplished using the rolling()method for pandas.Series:\n\nSpecify what we want to calculate over each window.\nUse the aggregator function mean() to calculate the average over each window\nthe parameter ‘5D’ indicates the window for our rolling average is 5 days.\nOuput is a pandas.Series\n\n\n# Calculate AQI rolling average over 5 days\nrolling_average = aqi_sb['aqi'].rolling('5D').mean()\n\n# View values\nrolling_average\n\ndate\n2017-01-01    39.000000\n2017-01-02    39.000000\n2017-01-03    49.666667\n2017-01-04    45.750000\n2017-01-05    44.000000\n                ...    \n2018-12-27    41.200000\n2018-12-28    38.600000\n2018-12-29    38.200000\n2018-12-30    38.200000\n2018-12-31    38.800000\nName: aqi, Length: 730, dtype: float64\n\n\nNow that we have the 5 day rolling averages, let’s add the means to a new column.\n\n# Add mean of AQI over 5-day rolling window to a new column\naqi_sb['five_day_average'] = rolling_average\n\n# View data frame to confirm new column\naqi_sb.head(3)\n\n\n\n\n\n\n\n\naqi\ncategory\ndefining_parameter\ndefining_site\nnumber_of_sites_reporting\nfive_day_average\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n2017-01-01\n39\nGood\nOzone\n06-083-4003\n12\n39.000000\n\n\n2017-01-02\n39\nGood\nPM2.5\n06-083-2011\n11\n39.000000\n\n\n2017-01-03\n71\nModerate\nPM10\n06-083-4003\n12\n49.666667\n\n\n\n\n\n\n\n\n\nVizualize\nOne way to visualize the data is to create a line plot showing both the daily AQI and the 5-day average (5-day average on top of the AQI).\n\n# Create AQI plot\nax = aqi_sb[['aqi', 'five_day_average']].plot(xlabel='Year', \n                                              ylabel='Air Quality Index (AQI)', \n                                              title='Air Quality Index (AQI) from 2017-2018')\n\n# Updating the legend with custom labels\nax.legend(['Daily AQI', '5-Day Average AQI'], loc='upper right')\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nDescription:\nNote the AQI spike in December at the time of the Thomas fire. The spike is less pronounced with the five-day average, but still very noticeable. It appears that the AQI returned to normal levels once the fire was extinguished."
  },
  {
    "objectID": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#data-references",
    "href": "blogs/2024-12-04-Thomas-Fire-Analysis/2017-Thomas-Fire-Analysis.html#data-references",
    "title": "2017 Thomas Fire Analysis",
    "section": "Data References",
    "text": "Data References\nCalifornia Department of Forestry and Fire Protection. (2017, December 4). Thomas Fire. California Department of Forestry and Fire Protection. https://www.fire.ca.gov/incidents/2017/12/4/thomas-fire\nMicrosoft. Landsat C2 L2 dataset. Planetary Computer. Retrieved November 19, 2024, from https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2\nU.S. Geological Survey (USGS). (2020). California Fire Perimeters (ALL). Data.gov. Retrieved November 19, 2024, from https://catalog.data.gov/dataset/california-fire-perimeters-all-b3436"
  },
  {
    "objectID": "blogs/2025-03-18-Loggerhead-Turtles/index.html",
    "href": "blogs/2025-03-18-Loggerhead-Turtles/index.html",
    "title": "Loggerhead Sea Turtle Nesting Trends",
    "section": "",
    "text": "Repository Link"
  },
  {
    "objectID": "blogs/2025-03-18-Loggerhead-Turtles/index.html#why-loggerhead-sea-turtles",
    "href": "blogs/2025-03-18-Loggerhead-Turtles/index.html#why-loggerhead-sea-turtles",
    "title": "Loggerhead Sea Turtle Nesting Trends",
    "section": "Why Loggerhead Sea Turtles?",
    "text": "Why Loggerhead Sea Turtles?\nIt all started in 2002, on Hawaii’s Big Island. I was 5 years old and just gotten back from snorkeling with my parents. The best part? The sea turtles, swimming gracefully amongst the coral reefs! Right then and there, I decided that sea turtles were my favorite animal. The next year, “Finding Nemo” came out in theaters and you better believe my excitement was out of this world when Marlin and Dory met Crush and Squirt and continued on their adventure to Sydney. The seed was planted and my personal love of sea turtles only grew as I matured and chose a career in the natural and data sciences.\nYes, sea turtles are cool to look at, but they also serve as ecosystem indicators. Their well-being, nesting trends, and overall health often reflect the health of their ocean and beach habitats. According to the International Union for Conservation of Nature (IUCN) and the U.S. Endangered Species Act (ESA), 6 out of the 7 species of sea turtle are listed as threatened, endangered, or critically endangered. Of these 6 species, loggerhead sea turtles (Caretta caretta) are one of the more widespread in range, as they inhabit beaches throughout temperate regions worldwide and are a highly migratory species. Loggerheads are listed as “vulnerable” on the IUCN red list, with a decreasing population.\nOcean warming and it’s impacts are hot topics in today’s political climate. As is the case with many reptilian species, the gender of loggerhead clutches are largely determined by temperature, with warmer temperatures generally leading to more female-dominant clutches. Sex imbalance can be an issue for future genetic viability of a population. Assessing loggerhead nesting trends is one way to determine how loggerheads might be affected by ocean warming, and potentially open up more avenues for research into ocean ecosystem health. Variation in loggerhead nesting between beaches may also lend insight into how certain beaches are handling climate change."
  },
  {
    "objectID": "blogs/2025-03-18-Loggerhead-Turtles/index.html#key-questions-where-are-loggerheads-nesting-around-the-world-is-loggerhead-nesting-changing-over-time-and-if-so-how",
    "href": "blogs/2025-03-18-Loggerhead-Turtles/index.html#key-questions-where-are-loggerheads-nesting-around-the-world-is-loggerhead-nesting-changing-over-time-and-if-so-how",
    "title": "Loggerhead Sea Turtle Nesting Trends",
    "section": "Key Questions: Where are loggerheads nesting around the world? Is loggerhead nesting changing over time and if so, how?",
    "text": "Key Questions: Where are loggerheads nesting around the world? Is loggerhead nesting changing over time and if so, how?\nThe data set used to address these questions is from “The effects of warming on loggerhead turtle nesting counts”, by Sousa-Guedes et al (2025) published on Dryad.\nThe data set contains 3 key variables:\n\nMann-Kendall: This number quantifies how much change in loggerhead turtle nesting (increase or decrease) a beach or region experienced. More on this in Question 3.\nrmu and country: Regional Management Unit, this number was used to assign countries to regions. I created a regions column from the data from the rmu and country column.\nGEOMETRY: Shapefile geometry for each beach/stretch of beach where nests were found."
  },
  {
    "objectID": "blogs/2025-03-18-Loggerhead-Turtles/index.html#design-elements",
    "href": "blogs/2025-03-18-Loggerhead-Turtles/index.html#design-elements",
    "title": "Loggerhead Sea Turtle Nesting Trends",
    "section": "Design elements:",
    "text": "Design elements:\nFor all three visualizations, I chose the font “quicksilver” as it just felt beachy (and legible). The theme elements for all three visualizations were refined with their color palette. Blues and sandy colors were selected to match the ocean theme, which also provide context for the entire info graphic. Additionally, text elements were modified in the theme for visualizations 1 and 3 for improved legibility.\nThe progression of the visualizations are laid out so that the reader should follow intuitively. Question 1 is broad; Question 2 is a bit more narrow building off of Question 1, and Question 3 is very narrow, also building off of the first two."
  },
  {
    "objectID": "blogs/2025-03-18-Loggerhead-Turtles/index.html#impact",
    "href": "blogs/2025-03-18-Loggerhead-Turtles/index.html#impact",
    "title": "Loggerhead Sea Turtle Nesting Trends",
    "section": "Impact",
    "text": "Impact\nMany local, indigenous, and tourist communities are heavily involved in the places represented in this info graphic. Tourism is a large component of funding sea turtle conservation research throughout the Caribbean and Gulf of Mexico, and should be promoted with sustainability, animal welfare, and local community impact in mind first."
  },
  {
    "objectID": "blogs/2025-03-18-Loggerhead-Turtles/index.html#the-infographic",
    "href": "blogs/2025-03-18-Loggerhead-Turtles/index.html#the-infographic",
    "title": "Loggerhead Sea Turtle Nesting Trends",
    "section": "The Infographic",
    "text": "The Infographic\nI used Canva to assemble all three plots into an informative infographic. I found their tools easy to use and it worked nicely with R."
  },
  {
    "objectID": "blogs/2025-03-18-Loggerhead-Turtles/index.html#question-1-where-in-the-world-are-loggerheads-nesting",
    "href": "blogs/2025-03-18-Loggerhead-Turtles/index.html#question-1-where-in-the-world-are-loggerheads-nesting",
    "title": "Loggerhead Sea Turtle Nesting Trends",
    "section": "Question 1: Where in the world are loggerheads nesting?",
    "text": "Question 1: Where in the world are loggerheads nesting?\nTo answer this question, I chose a bar chart, axes flipped, with a opacity value to represent frequency of nesting. The emphasis on this visualization is the top regions with the highest amount of nesting sites. I particularly want to draw attention to the Caribbean/Gulf of Mexico region, as the other two visualizations build on this region."
  },
  {
    "objectID": "blogs/2025-03-18-Loggerhead-Turtles/index.html#question-2-more-specifically-where-are-these-nests",
    "href": "blogs/2025-03-18-Loggerhead-Turtles/index.html#question-2-more-specifically-where-are-these-nests",
    "title": "Loggerhead Sea Turtle Nesting Trends",
    "section": "Question 2: More specifically, WHERE are these nests?",
    "text": "Question 2: More specifically, WHERE are these nests?\nTo best answer this question, I designed a map with the shape-files on top. All titles and text were ultimately removed, as they felt more like a distraction and took away from the map. The titles were then placed above the map in the info graphic, country annotations and arrows were added for further clarification."
  },
  {
    "objectID": "blogs/2025-03-18-Loggerhead-Turtles/index.html#question-3-how-has-loggerhead-nesting-changed-over-time-for-different-beaches",
    "href": "blogs/2025-03-18-Loggerhead-Turtles/index.html#question-3-how-has-loggerhead-nesting-changed-over-time-for-different-beaches",
    "title": "Loggerhead Sea Turtle Nesting Trends",
    "section": "Question 3: How has Loggerhead nesting changed over time for different beaches?",
    "text": "Question 3: How has Loggerhead nesting changed over time for different beaches?\nAs the data set did not provide a “year” column, the change over time element was present in the “mann-kendall” score column. The mann-kendall score, ranging from -0.2 to 0.8, tells us how nesting at a certain beach changed. Values below zero indicate that there was a decrease in nesting activity over time for a beach, values at zero indicate that there was no significant change over time fo a beach, and values above 0 indicate that there was an increase in nesting over time for a beach.\nTo best represent this data, I selected a line graph with a color gradient, and added in turtle nesting points (as a turtle hatching out of a shell icon) to represent each nesting site on a beach. Similar to visualization 2, annotations with arrows were added in for specific clarification."
  },
  {
    "objectID": "blogs/2025-03-18-Loggerhead-Turtles/index.html#code",
    "href": "blogs/2025-03-18-Loggerhead-Turtles/index.html#code",
    "title": "Loggerhead Sea Turtle Nesting Trends",
    "section": "Code",
    "text": "Code\nAll code for each of the infographic elements can be found in the code chunk below:\n\n\nCode\n# Load libraries\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(ggspatial)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(ggimage)\nlibrary(showtext)\nlibrary(grid)\n\n# Read in Turtle nesting data and font data --------------------------------------------------------------------------------------\n# Set the SHAPE_RESTORE_SHX config option\nSys.setenv(\"SHAPE_RESTORE_SHX\" = \"YES\")\n\n# Read the shapefile\nshapefile_path &lt;- \"C:/MEDS/EDS240-dataviz/Assignments/newby-eds240-HW4/data/nestingbeaches_GCB.shp\"\nturtles &lt;- st_read(shapefile_path) %&gt;% \n    janitor::clean_names()\n\n# Font options from google\nfont_add_google(\"Quicksand\", \"quicksand\") \nshowtext_auto()\n\n# Data Wrangling ------------------------------------------------------------------------------------------------------------\n# Check CRS\nst_crs(turtles)\n\n# Assume data into regional names\nturtles &lt;- turtles %&gt;% \n    mutate(region = case_when(rmu == 1 ~ \"Caribbean and Gulf of Mexico\",\n                              rmu == 2 ~ \"Southwest Atlantic\",\n                              rmu == 3 ~ \"Southeast Atlantic\",\n                              rmu == 4 ~ \"Mediterranean\",\n                              rmu == 5 ~ \"Arabian\",\n                              rmu == 8 ~ \"Eastern Indian\",\n                              TRUE ~ \"Unknown\")) %&gt;% \n    filter(region %in% c('Caribbean and Gulf of Mexico', 'Southeast Atlantic', 'Mediterranean', 'Arabian', 'Eastern Indian', 'Southwest Atlantic'))\n\n# Summarize unique nest counts per region\nregion_counts &lt;- turtles %&gt;%\n    st_drop_geometry() %&gt;% \n    group_by(region) %&gt;%\n    summarize(nest_count = n()) %&gt;%  # Count occurrences per region\n    mutate(opacity_val = nest_count / max(nest_count))  # Normalize opacity (0-1)\n\n# Join back to original data (so each region has its unique opacity)\nturtles &lt;- turtles %&gt;%\n    left_join(region_counts, by = \"region\")\n\n# Q1: World regions represented and their average nest count per year. ------------------------------------------------------------------------------- \n\nturtle_bar_plot &lt;- turtles %&gt;% \n    \n    ggplot(aes(x = fct_rev(fct_infreq(region)),\n               alpha = opacity_val))+\n    \n    geom_bar(fill = \"#EBD7A4\") +\n    \n    geom_text(stat = 'count', \n              aes(label=after_stat(count)),\n              hjust = 2,\n              size = 12,\n              color = \"black\",\n              family = 'quicksand',\n              fontface = \"bold\")+\n    \n    coord_flip()+\n    \n    geom_text(aes(x = region, y = 0, label = str_to_title(region)), \n             family = \"quicksand\",\n            size = 13, \n            hjust = -0.03,\n            nudge_y = 0.2) +\n    \n    labs(x = \" \",\n         y = \" \",\n         title = \"Where are Loggerheads Nesting?\",\n         subtitle = \" Average Loggerhead Nesting Counts (per year 1979 - 2023)\")+\n    \n    theme_void()+\n    \n    theme(\n        # text font\n        text = element_text(family = \"quicksand\"),\n        panel.grid.major.y = element_blank(),\n        \n        # adjust text size in plot\n        plot.title = element_text(face = \"bold\", color = \"white\", size = 40, hjust = 0.5),\n        plot.subtitle = element_text(face = \"bold\", size = 28, color = \"white\", hjust = 0.5),\n        axis.text = element_text(size = 20),\n\n        # Ocean colored background:\n        panel.background = element_rect(fill = \"#28808C\", color = NA),\n        plot.background = element_rect(fill = \"#28808C\", color = NA),\n        legend.background = element_rect(fill = \"#28808C\", color = NA),\n        \n        # Remove x and y axis labels\n        axis.text.x = element_blank(), \n        axis.ticks.x = element_blank(),\n        axis.text.y = element_blank(), \n        axis.ticks.y = element_blank(), \n    ) +\n    guides(alpha = \"none\")\n\n\n# Q2: Where are sea turtles nesting in the Caribbean and Gulf of Mexico? -------------------------------------------------------------------------------------\n\n# Filter to countries in the Caribbean/gulf of Mexico.\nmap_turtles_filtered &lt;- turtles %&gt;% \n    filter(region %in% c(\"Caribbean and Gulf of Mexico\"))\n\n# Get world basemap\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n# Make Map \ncaribbean_map &lt;- ggplot() +\n    # Add detailed basemap\n    geom_sf(data = world, fill = \"#EBD7A4\", color = \"#EBD7A4\") + \n    \n    # Add nesting layer\n    geom_sf(data = map_turtles_filtered, fill = \"#F50C0C\", color = \"#F50C0C\", lwd = 2) + \n    \n    # Set zoom to Gulf of Mexico and Caribbean\n    coord_sf(xlim = c(-100, -65), ylim = c(15, 33)) + \n    \n    # Apply a blank theme\n    theme_void() +\n    \n      theme(\n         # change background ocean color\n         panel.background = element_rect(fill = \"#28808c\", color = NA)\n    )\n\n\n\n# Q3: what is the variation in the mann-kendall slopes in the Caribbean/gulf of mexico? ------------------------------------------------------\n\nmann_kendall_plot &lt;- map_turtles_filtered %&gt;%\n    \n  ggplot(aes(x = mann_kendal, \n             y = region)) +\n    \n  geom_line(aes(color = mann_kendal), \n            size = 4) +  \n    \n    # Use ggimage for turtle icons\n  geom_image(aes(image = image), size = 0.13) +\n    \n    # Gradient color and gradient color legend\n  scale_color_gradient2(low = \"green\", \n                        mid = \"lightblue\", \n                        high = \"#438D80\", \n                        midpoint = 0.25,\n                        guide = guide_colorbar(title = NULL,\n                                               barwidth = 21,\n                                               barheight = 0.5),\n                        breaks = c(-0.17, 0, 0.5),\n                        labels = c(\"Decrease\", \"No Change\", \"Increase\")) + \n    \n    # label axes\n  labs(x = \"Mann-Kendall Slope\",\n       y = \"\",\n       title = \"There's Variation Across Beaches in the Caribbean and Gulf of Mexico\",\n       subtitle = \"What does this variation mean? Some beaches may handle the effects of climate change better than others\") +\n    \n  theme_minimal() +\n    \n  theme(legend.position = \"bottom\",\n        # text font\n        text = element_text(family = \"quicksand\"),\n        \n        # Sand colored background:\n        panel.background = element_rect(fill = \"#EBD7A4\", color = NA),\n        plot.background = element_rect(fill = \"#EBD7A4\", color = NA),\n        legend.background = element_rect(fill = \"#EBD7A4\", color = NA),\n        \n        # adjust text size in plot\n        plot.title = element_text(face = \"bold\", size = 31, hjust = 0.5),\n        plot.subtitle = element_text(size = 22, hjust = 0.5),\n        axis.title.x = element_text(size = 20),\n        axis.text = element_text(size = 20),\n        legend.text = element_text(size = 20),\n        \n        # Hide labels\n        axis.text.y = element_blank(),  # Hides y-axis labels\n        axis.ticks.y = element_blank(),  # Hides y-axis ticks\n        panel.grid.minor = element_blank() # remove minor grid lines\n    )"
  },
  {
    "objectID": "blogs/2025-03-18-Loggerhead-Turtles/index.html#thank-you",
    "href": "blogs/2025-03-18-Loggerhead-Turtles/index.html#thank-you",
    "title": "Loggerhead Sea Turtle Nesting Trends",
    "section": "Thank you!",
    "text": "Thank you!\nI hope you learned something cool about loggerheads today! If you are interested in supporting or learning more about loggerhead conservation in the countries displayed in visualization 2, please explore the following links:\n\nLoggerhead Marinelife Center, Florida, USA\nXcacel-Xcacelito: Sea Turtle Sanctuary, Mexico\nDepartment of Environment, Cayman Islands Government"
  },
  {
    "objectID": "blogs/2025-03-18-Loggerhead-Turtles/index.html#sources",
    "href": "blogs/2025-03-18-Loggerhead-Turtles/index.html#sources",
    "title": "Loggerhead Sea Turtle Nesting Trends",
    "section": "Sources",
    "text": "Sources\n\nIUCN. (2025). Caretta caretta (Loggerhead Turtle). The IUCN Red List of Threatened Species 2025: e.T3897A119333622. Retrieved from https://www.iucnredlist.org/species/3897/119333622\nSousa-Guedes, Diana; Campos, João C.; Bessa, Filipa et al. (2025). The effects of warming on loggerhead turtle nesting counts [Dataset]. Dryad. https://doi.org/10.5061/dryad.b8gtht7n5\nU.S. Fish and Wildlife Service. (1973). Endangered Species Act of 1973, as amended. Retrieved from https://www.fws.gov/endangered/laws-policies/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Eva Newby",
    "section": "",
    "text": "Eva Newby is a graduate student in the UC Santa Barbara Bren School of Environmental Science and Management, working towards a Master’s degree in Environmental Data Science. Eva graduated with Regents Scholar distinction from UC Davis (2019) with a B.S. in Animal Science and a specialization in Animal Behavior. Since graduation, she has been volunteering at North America’s largest refugee camp in Tijuana, Mexico and working as a biologist in the environmental consulting field. In addition to her responsibilities as a biologist, Eva became the head drone pilot for the Southern California region, exposing her to even more of California’s diverse ecosystems. Drone imagery data synthesis initially sparked her interest in the data science field, and the curiosity to use data science to further inform sound environmental decision making drove her to apply to the Bren School. Eva additionally plans to use her data science skills to help address food insecurity in impoverished communities.\nOutside of her professional career, Eva enjoys the great outdoors through surfing, biking, rock climbing, snowboarding, hiking, and petting as many friendly animals as possible."
  },
  {
    "objectID": "blogs/2024-10-18-intro-post/index.html",
    "href": "blogs/2024-10-18-intro-post/index.html",
    "title": "Blog post title",
    "section": "",
    "text": "I am going to insert a footnote here[^1] [^1]: here is a new footnote"
  },
  {
    "objectID": "blogs/2024-10-18-intro-post/index.html#this-is-my-first-section",
    "href": "blogs/2024-10-18-intro-post/index.html#this-is-my-first-section",
    "title": "Blog post title",
    "section": "",
    "text": "I am going to insert a footnote here[^1] [^1]: here is a new footnote"
  },
  {
    "objectID": "blogs/2024-10-18-intro-post/index.html#this-is-my-second-section",
    "href": "blogs/2024-10-18-intro-post/index.html#this-is-my-second-section",
    "title": "Blog post title",
    "section": "This is my second section",
    "text": "This is my second section\nHere’s my next paragraph1\nI’m citing Sam(Csik 2021)\nHere is more random texts. I am going to cite a journal article now. (Gaynor et al. 2022)"
  },
  {
    "objectID": "blogs/2024-10-18-intro-post/index.html#footnotes",
    "href": "blogs/2024-10-18-intro-post/index.html#footnotes",
    "title": "Blog post title",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere is my second footnote↩︎"
  },
  {
    "objectID": "resources.html#selecting-a-color-palette",
    "href": "resources.html#selecting-a-color-palette",
    "title": "All of my Favorite Resources",
    "section": "Selecting a Color Palette",
    "text": "Selecting a Color Palette\nCoolors is one of my go-tos. Just click the space bar to change the colors, and have fun!"
  }
]